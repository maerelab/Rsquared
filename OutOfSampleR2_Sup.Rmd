---
title: "Supplementary material for 'The out-of-sample \\rsq: estimation and inference'"
author: "Stijn Hawinkel, Willem Waegeman and Steven Maere"
output: 
  pdf_document:
    number_sections: true
    keep_tex: yes
    includes:
            in_header: R2.sty
---

\tableofcontents

\beginsupplement{0}

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache = TRUE, autodep = TRUE, warning = FALSE, 
                      message = FALSE, echo = FALSE, eval = TRUE, tidy = TRUE,
                      fig.width = 8, fig.height = 5, purl = TRUE, 
                      fig.show = "hold", fig.pos = "p")
libs = c("ggplot2", "parallel", "reshape2", "nlme", "glmnet", "xtable")#, "boot")
for (i in libs){
  library(i, character.only = TRUE, quietly = TRUE)
};rm(i, libs)
theme_set(theme_bw())
for(i in list.files("R")){source(file.path("R", i))};rm(i)
nCores = 4
lmeCon = lmeControl(opt = "optim", maxIter = 5e2, msVerbose = FALSE,
                   msMaxIter = 5e2, niterEM = 1e3, msMaxEval=1e3)
methodLevels <- c("bootRhos", "bootRhosParam", "cvRhos", "jnRhos", "oracleRho", "bootSEs", "bootParamSEs", "oracleSE", "bootPercentile", "bootPercentileParam", "bootparamPercentile", "boot", "bootparam", "BCa", "BCaParam", "bootRhos_Log", "bootRhosParam_Log", "cvRhos_Log", "jnRhos_Log",  "oracleRho_Log", "bootSEs_Log", "bootParamSEs_Log", "oracleSE_Log")
methodLabels <- c("Delta method SE (nonparametric bootstrap)", "Delta method SE (parametric bootstrap)", "Delta method SE (cross-validation)", "Delta method SE (jackknife)", "Delta method SE (oracle)", "Bootstrap SE (nonparametric)", "Bootstrap SE (parametric)", "Oracle SE", "Percentile bootstrap", "Percentile parametric bootstrap", "Percentile parametric bootstrap", "Percentile bootstrap", "Percentile parametric bootstrap", "BCa", "BCa (parametric)", "Delta method (bootstrap) log", "Delta method (parametric bootstrap) log", "Delta method (cross-validation) log", "Delta method (jackknife) log", "Delta method (oracle) log", "Bootstrap SE (nonparametric, log)", "Bootstrap SE (parametric, log)", "Studentized oracle log")
methodColours = c("Delta method SE (nonparametric bootstrap)" = "red", "Delta method SE (parametric bootstrap)" = "orange", "Delta method SE (cross-validation)" = "magenta2", "Delta method SE (jackknife)" = "#993300", "Delta method SE (oracle)" = "#669900", "Bootstrap SE (nonparametric)" = "blue", "Bootstrap SE (parametric)" = "mediumpurple4", "Oracle SE" = "black", "Percentile bootstrap" = "chartreuse4", "Percentile parametric bootstrap" = "darkgreen", "BCa" = "purple", "BCa (parametric)" = "magenta2")
SEplot =  methodLabels[grepl("SE", methodLabels) & !grepl("oracle", methodLabels, ignore.case = TRUE) & !grepl("cross-validation", methodLabels, ignore.case = TRUE)]
rhosPlot = methodLabels[1:4]
dir.create("simResults")
dir.create("Results")
```

```{r simSetup}
n = 50#Sample size
p = 1e3 #Number of features
nOuterFolds = 10
nInnerFolds = nOuterFolds - 1
sdY = 1 #Residual SD
alpha = 0.5
sigLevel = 0.05
Quants = c("lower"= -1, "upper" = 1)*qnorm(1-sigLevel/2)
MCestReps = 5e3 #Number of Monte-Carlo replicates to find true MSEs
signal = 10; fracSignal = 0.01
betas1e3 = c(rep(signal,p*fracSignal), rep(0, p*(1-fracSignal))) #Keep Betas fixed
p2 = 5e2; betas5e2 = c(rep(signal,p2*fracSignal), rep(0, p2*(1-fracSignal))) #Keep Betas fixed
nFolds = c(5, 10); names(nFolds) = nFolds
expvec = c((1-exp(-1)), exp(-1))
nTest = 1e4
```

```{r r2ciSweepparametersweep}
samSize = c(20, 30, 50, 100)
betas = c(0, 0.5, 1, 1.5)
bootRepsSweep = c(10, 50, 100, 500)
cvSplitsSweep = c(1, 25, 100, 200)
sweepReps = 1e3
gridSweep = expand.grid('samSize' = samSize, 'betas' = betas, 'bootReps' = bootRepsSweep, 'cvSplitsSweep' = cvSplitsSweep)
quantsSweep = c(sigLevel/2, 1-sigLevel/2)
```

```{r simulSweep}
if(!file.exists(r2ciSweepFileAlt <- "simResults/r2ciSweepFileAlt.RData")){
  r2ciSweepAlt = mclapply(mc.cores = nCores, mc.preschedule = FALSE, seq_len(nrow(gridSweep)), function(i){
    cat("Param combo", i, "\t")
    testData = genDat(n = nTest, 1, betas = gridSweep[i, 'betas'])
    trueMSE = vapply(FUN.VALUE = double(1), integer(MCestReps), function(j){
      genDataAndgetTestMSE(gridSweep[i, 'samSize'], 1, betas = gridSweep[i, 'betas'], testDat = testData)[[1]]
    })
    margVar = var(testData$y)
    resList = lapply(seq_len(sweepReps), function(r){
        trainDat = genDat(gridSweep[i, 'samSize'], 1, betas = gridSweep[i, 'betas'])
        seEsts = nestedCV(trainDat, nOuterFolds, cvSplits = gridSweep[i, 'cvSplitsSweep'])
        bootEsts = bootCV(trainDat, nOuterFolds, gridSweep[i, 'bootReps'], cvSplits = gridSweep[i, 'cvSplitsSweep'])
        bootEstsParam = bootCV(trainDat, nOuterFolds, gridSweep[i, 'bootReps'], cvSplits = gridSweep[i, 'cvSplitsSweep'], paramBoot = TRUE)
        jackKnifeEsts = t(jackKnifeCV(trainDat, nOuterFolds, cvSplits = gridSweep[i, 'cvSplitsSweep']))
        list("seEsts" = seEsts, "bootEsts" = bootEsts, "bootEstsParam" = bootEstsParam, 
             "jackKnifeEsts" = jackKnifeEsts, "margVar" = var(trainDat$y))
    })
    list('resList' = resList, 'trueMSE' = trueMSE, "trueMargVar" = margVar)
  })
  save(r2ciSweepAlt, file = r2ciSweepFileAlt)
} 
```

```{r processSweep}
if(!file.exists(sweepProcessFile <- 'simResults/sweepProcessFile.RData')){
    load(r2ciSweepFileAlt) 
    sweepProcess = lapply(seq_len(nrow(gridSweep)), function(i){
        obj = r2ciSweepAlt[[i]]
        oracleRho = cor(t(sapply(obj$resList, function(x) c(x[["seEsts"]][[1]]["Bates", "MSEhat"], x[["margVar"]]))))[1,2]
        out = lapply(obj$resList, function(xxx, oracleRho){
            with(xxx, {
            n = gridSweep[i, "samSize"]
            margVarOut = margVar*(n+1)/n
            rhosMat = cbind("bootRhos" = vapply(FUN.VALUE = double(1), seq_along(seEsts), function(x) {
                out = sapply(bootEsts, function(w){w[x, ]})
                cor(out[1,], out[2,])
            }),
            "bootRhosParam" = vapply(FUN.VALUE = double(1), seq_along(seEsts), function(x) {
                out = sapply(bootEstsParam, function(w){w[x, ]})
                cor(out[1,], out[2,])
            }),
            "cvRhos" = vapply(FUN.VALUE = double(1), seEsts, function(x) x[2,"CovAndCor"]),
            "jnRhos" = cor(jackKnifeEsts[, 1], jackKnifeEsts[, 2]),
            "oracleRho" = oracleRho)
            MSEs = vapply(FUN.VALUE = double(1), seEsts, function(x) x["Bates", "MSEhat"])
            MSEsSE = vapply(FUN.VALUE = double(1), seEsts, function(x) x["Bates", "SE"])
            bootEstsR2 = sapply(bootEsts, function(x) 1-x[, 1]/x[, 2]*n/(n+1))
            bootEstsR2param = sapply(bootEstsParam, function(x) 1-x[, 1]/x[, 2]*n/(n+1)) #The percentile bootstrap
            sesMat = c(apply(rhosMat, 2, function(rho){
                vapply(FUN.VALUE = double(1), seq_along(seEsts), function(j){
                    RsquaredSE(MSE = seEsts[[j]]["Bates", "MSEhat"], n = gridSweep[i, 'samSize'], margVar = margVarOut,
                               SEMSE = seEsts[[j]]["Bates", "SE"], rhoBoot = rho[j])[2]
                })
            }),
            "bootSEs" = sd(bootEstsR2),
            "bootParamSEs" = sd(bootEstsR2param)
            )
            sesMatLog = c(apply(rhosMat, 2, function(rho){
                vapply(FUN.VALUE = double(1), seq_along(seEsts), function(j){
                    RsquaredSE(MSE = seEsts[[j]]["Bates", "MSEhat"], n = n, margVar = margVarOut,
                               SEMSE = seEsts[[j]]["Bates", "SE"], rhoBoot = rho[j], Log = TRUE)[2]
                })
            }),
            "bootSEs" = sd(log(1-bootEstsR2)),
            "bootParamSEs" = sd(log(1-bootEstsR2param))
            )
            bootQuantiles = quantile(bootEstsR2, quantsSweep)
            bootQuantilesParam = quantile(bootEstsR2param, quantsSweep)
            jackKnifeEsts[, 2] = jackKnifeEsts[, 2]*(n+1)/n
            jackKnifeEstsR2 = 1-jackKnifeEsts[, 1]/jackKnifeEsts[, 2]
            BCa = buildBCa(Rsq <- 1-MSEs/margVarOut, bootEstsR2, jackKnifeEstsR2, sigLevel)
            BCaparam = buildBCa(Rsq, bootEstsR2param, jackKnifeEstsR2, sigLevel)
            list("MSEhat" = MSEs, "MSEsSE" = MSEsSE, "margVar" = margVarOut, "ses" = sesMat, "sesLog" = sesMatLog, 
                 bootQuants = rbind("bootPercentile" = bootQuantiles, "bootPercentileParam" = bootQuantilesParam, "BCa" = BCa, "BCaParam" = BCaparam))
        })
    }, oracleRho = oracleRho)
    oracleSE = sd(sapply(out, function(x) x[["MSEhat"]]/x[["margVar"]]))
    lapply(out, function(x) {x$ses = c(x$ses, "oracleSE" = oracleSE)
        x$true = c("trueMSE" = mean(obj[["trueMSE"]]), "trueMargVar" = obj[["trueMargVar"]]*(n+1)/n)
    x}) #Use SD from estimation rather than oracle (different number of cvSplits)
    })
    save(sweepProcess, file = sweepProcessFile)
} else load(sweepProcessFile)
if(!file.exists(sweepRhosFile <- 'simResults/sweepRhosFile.RData')){ 
    load(r2ciSweepFileAlt)
    rhosProc = lapply(seq_len(nrow(gridSweep)), function(i){
        obj = r2ciSweepAlt[[i]]
        oracleRho = cor(t(sapply(obj$resList, function(x) c(x[["seEsts"]][[1]]["Bates", "MSEhat"], x[["margVar"]]))))[1,2]
        out = t(sapply(obj$resList, function(xxx, oracleRho){
            with(xxx, {
            rhosMat = c("bootRhos" = vapply(FUN.VALUE = double(1), seq_along(seEsts), function(x) {
                out = sapply(bootEsts, function(w){w[x, ]})
                cor(out[1,], out[2,])
            }),
            "bootRhosParam" = vapply(FUN.VALUE = double(1), seq_along(seEsts), function(x) {
                out = sapply(bootEstsParam, function(w){w[x, ]})
                cor(out[1,], out[2,])
            }),
            "cvRhos" = vapply(FUN.VALUE = double(1), seEsts, function(x) x[2,"CovAndCor"]),
            "jnRhos" = cor(jackKnifeEsts)[2],
            "oracleRho" = oracleRho)
        })
    }, oracleRho = oracleRho))
    })
    save(rhosProc, file = sweepRhosFile)
} else load(sweepRhosFile)
```

```{r bootparametersweep}
bootRepsSweepBoot = c(25, 100, 200)
sweepReps = 1e3
gridSweepBoot = expand.grid('samSize' = samSize, 'betas' = betas,
                            'bootReps' = bootRepsSweepBoot, "bootRepsOuter" = bootRepsSweep)
```

```{r simulSweepBoot}
if(!file.exists(bootSweepFile <- "simResults/bootSweep.RData")){
  bootSweep = mclapply(mc.cores = nCores, mc.preschedule = FALSE, seq_len(nrow(gridSweepBoot)), function(i){
    cat("ParamBoot combo", i, "\t")
    testData = genDat(n = nTest, 1, betas = gridSweepBoot[i, 'betas'])
    trueMSE = vapply(FUN.VALUE = double(1), integer(MCestReps), function(j){
      genDataAndgetTestMSE(gridSweepBoot[i, 'samSize'], 1, betas = gridSweepBoot[i, 'betas'], testDat = testData)[[1]]
    })
    margVar = var(testData$y)
    resList = lapply(seq_len(sweepReps), function(r){
        trainDat = genDat(gridSweepBoot[i, 'samSize'], 1, betas = gridSweepBoot[i, 'betas'])
        bootObjOOB = fullBoot(trainDat, gridSweepBoot[i, 'bootReps'], "oob")
        bootObjOOBests = processOob(bootObjOOB)
        bootObj632 = fullBoot(trainDat, bootReps = gridSweepBoot[i, 'bootReps'], bootMethod = "632", 
                              bootRepsOuter = gridSweepBoot[i, 'bootRepsOuter'], jackknife = TRUE)
        bootObj632ests = process632(bootObj632, oobObj = bootObjOOBests$procOb)
        list("bootObj632ests" = bootObj632ests, "margVar" = var(trainDat$y))
    })
    list('resList' = resList, 'trueR2' = trueMSE, "trueMargVar" = margVar)
  })
  save(bootSweep, file = bootSweepFile)
} 
```

```{r processSweepBoot}
if(!file.exists(sweepProcessBootFile <- 'simResults/sweepProcessBootFile.RData')){
    load(bootSweepFile) 
    sweepBootProcess = lapply(seq_len(nrow(gridSweepBoot)), function(i){
        obj = bootSweep[[i]]
        n = gridSweepBoot[i, "samSize"]
        oracleRho = cor(t(sapply(obj$resList, function(x) c(x[["bootObj632ests"]][["procOb"]]["MSEhat",], x[["margVar"]]))))[1,2]
        out = lapply(obj$resList, function(xxx, oracleRho){
            with(xxx, {
                margVarOut = margVar*(n+1)/n
            rhosMat = c("bootRhos" = cor(use = "complete.obs", MSEsBoot <- bootObj632ests$procBoot, bootObj632ests$margVarBoot), "bootRhosParam" = cor(use = "complete.obs", MSEsBootParam <- bootObj632ests$procBootParam, bootObj632ests$margVarBootParam),
                      "jnRhos" = cor(use = "complete.obs", bootObj632ests$procJack, bootObj632ests$margVarJack),
            "oracleRho" = oracleRho)
            MSEsSE = bootObj632ests$procOb["SEhat", ]
            bootEstsR2 = 1-MSEsBoot/bootObj632ests$margVarBoot*n/(n+1)
            bootEstsR2param = 1-MSEsBootParam/bootObj632ests$margVarBootParam*n/(n+1)
            sesMat = c(sapply(rhosMat, function(rho){
                vapply(FUN.VALUE = double(1), seq_len(ncol(bootObj632ests$procOb)), function(j){
                    RsquaredSE(MSE = bootObj632ests$procOb["MSEhat", j], n = n, margVar = margVarOut,
                               SEMSE = if(!is.na(bootObj632ests$procOb["SEhat", j])) {
                                   bootObj632ests$procOb["SEhat", j]
                                   } else {
                                   bootObj632ests$procOb["SEhatNaive", j]
                               }, rhoBoot = rho)[2]
                })
                #If se fails use naive version
            }), "bootSEs" = sd(bootEstsR2, na.rm = TRUE), "bootParamSEs" = sd(bootEstsR2param, na.rm = TRUE)
            )
            bootQuantiles = quantile(bootEstsR2, quantsSweep, na.rm = TRUE)
            bootQuantilesParam = quantile(bootEstsR2param, quantsSweep, na.rm = TRUE)
            BCa = buildBCa(Rsq <- 1-bootObj632ests$procOb["MSEhat", ]/margVarOut, bootEstsR2, jackPars = jackRsq <- 1-bootObj632ests$procJack/bootObj632ests$margVarJack*n/(n+1), sigLevel)
            BCaParam = buildBCa(Rsq <- 1-bootObj632ests$procOb["MSEhat", ]/margVarOut, bootEstsR2param, jackPars = jackRsq, sigLevel)
            list("MSEhat" = mean(MSEsBoot, na.rm = TRUE), "MSEsSE" = MSEsSE, "margVar" = margVarOut, "ses" = sesMat,
                 bootQuants = rbind("bootPercentile" = bootQuantiles, "bootPercentileParam" = bootQuantilesParam, 
                                    "BCa" = BCa, "BCaParam" = BCaParam))
        })
    }, oracleRho = oracleRho)
    oracleSE = sd(sapply(out, function(x) x[["MSEhat"]]/x[["margVar"]]))
    lapply(out, function(x) {
        x$ses = c(x$ses, "oracleSE" = oracleSE)
        x$true = c("trueMSE" = mean(obj[["trueR2"]]), "trueMargVar" = obj[["trueMargVar"]]*(n+1)/n)
    x})
    })
    save(sweepBootProcess, file = sweepProcessBootFile)
} else load(sweepProcessBootFile) 
```

```{r sweepProcBiasSE, fig.cap = "Log10 of the geometric mean of the ratios of estimated to approximated true standard error (SE) of the \\rsq (y-axis) for cross-validation as a function of estimation method (colour), sample size (x-axis), number of bootstraps (top panels), signal strength (side panels) and number of cross-validation splits (linetype).  The bias of the SE estimation is seen to decrease with the number of cross-validation splits and signal strength. \\label{fig:biasUni}", fig.height = 6}
biasProcSE = Reduce(f = rbind, lapply(seq_along(sweepProcess), function(x){
    biasSE = sapply(sweepProcess[[x]], function(y){
        trueR2se = y$ses["oracleSE"]
        estR2se = y$ses[c("bootRhos", "bootRhosParam", "jnRhos", "bootSEs", "bootParamSEs")]
        estR2se/trueR2se
    })
    cbind("Bias" = unname(rowMeans(log10(biasSE))), "Method" = rownames(biasSE), gridSweep[x,])
}))
linetypes = c("solid", "dashed", "dotdash", "dotted"); names(linetypes) = cvSplitsSweep
numSplitsShow = cvSplitsSweep[2:4]
linetypesShow = linetypes[2:4]
biasProcSE$Method = factor(biasProcSE$Method, levels = methodLevels, labels = methodLabels)
biasSEplot = ggplot(data = biasProcSE[with(biasProcSE, cvSplitsSweep %in% numSplitsShow & bootReps >= 50 & betas %in% c(0, 1, 1.5)), ], aes_string(y = "Bias", x = "samSize", colour = "Method", linetype = "factor(cvSplitsSweep)")) + geom_line() + facet_grid(betas ~ bootReps, scale = "free_y") + guides(linetype = guide_legend("Number of cross-validation splits")) + 
    xlab("Sample size") + ylab(bquote('Log10 of the geometric mean of the ratio of estimated to approximated true SE of the '*R^2)) + geom_hline(yintercept = 0, linetype = "dotted") + scale_linetype_manual(values = linetypesShow) + scale_colour_manual(values = methodColours[names(methodColours) %in% SEplot]) + scale_x_continuous(breaks = samSize) + theme(axis.text.x = element_text(angle=60))
ggsave(biasSEplot, file = "Graphs/biasSE.pdf", height = 6.5)
```

```{r risweepCov, fig.cap = 'Coverage of the confidence intervals (y-axis) for cross-validation for different sample sizes (x-axis), methods (colour), signal strength (side panel) and number of bootstrap replicates (top panels) for 200 repeats of the cross-validation splits. The dotted line indicates the nominal coverage of 95\\%.\\label{fig:sweepCov}', fig.height = 6, fig.width = 8}
r2cisweepCI = lapply(seq_along(sweepProcess), function(i){ 
    lapply(sweepProcess[[i]], function(x){
        R2 = 1-x[['MSEhat']]/x[['margVar']]*n/(n+1)
        CI = R2 + outer(x[['ses']], Quants)
        CI = rbind(CI, x[["bootQuants"]])
        #Log transform
        CIlog = log(1-R2)+ outer(x[['sesLog']], Quants[2:1])
        rownames(CIlog) = paste0(rownames(CIlog), "_Log")
        CI = rbind(CI, 1-exp(CIlog))
        CI[, 2] = sapply(CI[, 2], min, 1)
        CI 
    })
})
r2cisweepNonCov = vapply(seq_along(sweepProcess), FUN.VALUE = array(TRUE, dim = c(numRow <- nrow(r2cisweepCI[[1]][[1]]),2, sweepReps)), function(i){
    trueR2 = 1 - sweepProcess[[i]][[1]]$true[["trueMSE"]]/sweepProcess[[i]][[1]]$true[["trueMargVar"]]
    vapply(r2cisweepCI[[i]], FUN.VALUE = matrix(TRUE, nrow(r2cisweepCI[[i]][[1]]),2), function(CI){
        cbind("under" = trueR2 < CI[,1], "over" = trueR2 > CI[,2])
    })
})
r2cisweepCov = !apply(r2cisweepNonCov, c(1,3,4), any, na.rm = TRUE)
r2cisweepWidth = vapply(seq_along(sweepProcess), FUN.VALUE = matrix(0, numRow, sweepReps), function(i){
    sapply(r2cisweepCI[[i]], function(CI){
        apply(CI, 1, diff)
    })
})
r2cisweepCovSum = t(apply(r2cisweepCov, c(1,3), mean, na.rm = TRUE));r2cisweepWidthSum = t(apply(r2cisweepWidth, c(1,3), mean, na.rm = TRUE))
sweepSum = cbind(gridSweep, r2cisweepCovSum)
sweepSumMolt = melt(sweepSum, id.vars = names(gridSweep), value.name = "Coverage", variable.name = 'Method')
sweepSumMolt$betas = factor(sweepSumMolt$betas)
sweepSumMolt$Method = factor(sweepSumMolt$Method, levels = methodLevels, 
                             labels = methodLabels)
labels2plot = c("Delta method SE (nonparametric bootstrap)", "Delta method SE (parametric bootstrap)", "Delta method SE (jackknife)", "Bootstrap SE (nonparametric)", 
                "Bootstrap SE (parametric)", "Percentile bootstrap", "BCa", "Percentile parametric bootstrap", "BCa (parametric)")
#Log-transformation does not help
covPlot = ggplot(data = sweepSumMolt[with(sweepSumMolt, cvSplitsSweep==200 & Method %in% labels2plot & bootReps > 10 & betas %in% c(0, 1, 1.5)),], aes(x = samSize, y = Coverage, col = Method)) + geom_line() + facet_grid(betas ~ bootReps, scale = "free_y") + 
    xlab("Sample size") + geom_hline(yintercept = 1-sigLevel, linetype = 'dotted') + ylab(bquote("Coverage of the 95% confidence interval for "*R^2)) +
    scale_colour_manual(values = methodColours[names(methodColours) %in% labels2plot]) + scale_x_continuous(breaks = samSize) + theme(axis.text.x = element_text(angle=60))
ggsave("Graphs/covPlot.pdf")
```

```{r oneDimCombiPlot, include = FALSE}
moltBias = melt(biasProcSE, id.vars = c("samSize", "betas", "bootReps", "cvSplitsSweep", "Method"))
moltCov = melt(sweepSumMolt, id.vars = c("samSize", "betas", "bootReps", "cvSplitsSweep", "Method"))
moltAll = rbind(moltCov, moltBias)
biasName = "Log10(estimated/true standard error)"
moltAll$variable = factor(as.character(moltAll$variable), levels = c("Bias", "Coverage"), labels = c(biasName, "Coverage"), ordered = TRUE)
moltAll = droplevels(moltAll)
dfLine = data.frame("variable" = c(biasName, "Coverage"), "yintercept" = c(0, 1-sigLevel))
dfLine$variable = factor(as.character(dfLine$variable), levels = c(biasName, "Coverage"), labels = c(biasName, "Coverage"), ordered = TRUE)
OneDimplot = ggplot(data = moltAll[with(moltAll, cvSplitsSweep == 200 & bootReps == 500 & Method %in% labels2plot), ], aes_string(y = "value", x = "samSize", colour = "Method")) + geom_line() + facet_grid(variable~betas, scale = "free_y") + guides(linetype = guide_legend("Number of cross-validation splits")) + 
    xlab("Sample size") + ylab("Diagnostic") + 
    geom_hline(data = dfLine, aes(yintercept = yintercept), linetype = "dotted") + scale_colour_manual(values = methodColours[names(methodColours) %in% labels2plot]) + 
    scale_x_continuous(breaks = samSize) + theme(axis.text.x = element_text(angle=60))
ggsave(OneDimplot, file = "Graphs/oneDimCombi.pdf", height = 5.3, width = 9)
```

```{r realDataBrasNap}
#Brassica napus
load("R2data/geneExprBrasNap.RData")
load("R2data/sampleDataBrasNap.RData")
phenId1R2 = c("leafWidth_das.76_leafBot.8", "branchesCount_das.278", "leavesCount_das.74", "rootWidth_das.278", "seedsCount_das.278")
names(phenId1R2) = c("Leaf_8_width", "Total_branch_count", "Number_of_leaves", "Root_system_width", "Number_of_seeds")
#Choose some phenotypes with high and some with low performance
id = !duplicated(phenData1$plantId)
phenData1 = phenData1[id,]; rlogBras1 = rlogBras1[rownames(phenData1),]
topFeats = 5e3; cvSplitsReal = 1e2; bootRepsReal = 50
if(!file.exists(MultiMSEcvFile <- "Results/MultiMSECVr2.RData")){
    MultiMSECV = lapply(phenId1R2, function(phen){
        dat = list("x" = rlogBras1, "y" = phenData1[,phen])
        dat$y = dat$y[id <- !is.na(dat$y)];dat$x = dat$x[id,]
        #Use top most expressed 5000 features
        relExpr = colSums(dat$x)
        dat$x = dat$x[,relExpr >= sort(relExpr, decreasing = TRUE)[topFeats]]
        multiMod = nestedCVglmnet(dat, nOuterFolds, alpha = alpha, cvSplits = cvSplitsReal)
        bootRes = vapply(FUN.VALUE = double(2), seq_len(bootRepsReal), function(cvs){
              id = sample(seq_along(dat$y), replace = TRUE)
              dat$y = dat$y[id];dat$x=dat$x[id,]
              MSE = mean(unlist(singleCVglmnet(dat, nOuterFolds, cvSplits = cvSplitsReal, alpha = alpha)))
              c("MSE" = MSE, "margVar" = var(dat$y))
        })
        jackRes = vapply(FUN.VALUE = double(2), seq_along(dat$y), function(idOut){
              dat$y = dat$y[-idOut];dat$x=dat$x[-idOut,]
              MSE = mean(unlist(singleCVglmnet(dat, nOuterFolds, cvSplits = cvSplitsReal, alpha = alpha)))
              c("MSE" = MSE, "margVar" = var(dat$y))
        })
        list("multiMod" = multiMod, "bootRes" = bootRes, "jackRes" = jackRes)
    })
    save(MultiMSECV, file = MultiMSEcvFile)
} else load(MultiMSEcvFile)
margVars = sapply(phenId1R2, function(vv) {var(phenData1[[vv]], na.rm = TRUE)})
MSEsReal = sapply(names(phenId1R2), function(x) MultiMSECV[[x]]$multiMod["Bates", "MSEhat"])
samSizes = sapply(phenId1R2, function(pp){sum(!is.na(phenData1[[pp]]))})
Cors = sapply(names(phenId1R2), function(pp){cor(MultiMSECV[[pp]]$bootRes["MSE", ], MultiMSECV[[pp]]$bootRes["margVar", ])})
CorsJN = sapply(names(phenId1R2), function(pp){cor(MultiMSECV[[pp]]$jackRes["MSE", ], MultiMSECV[[pp]]$jackRes["margVar", ])})
bootSEsBras = sapply(names(phenId1R2), function(pp){sd(MultiMSECV[[pp]]$bootRes["MSE", ]/ MultiMSECV[[pp]]$bootRes["margVar", ])})
R2sSEs = t(sapply(names(phenId1R2), function(pp){
    RsquaredSE(MSEsReal[pp], margVars[pp], SEMSE = MultiMSECV[[pp]]$multiMod["Bates", "SE"], 
               n = samSizes[[pp]], rhoBoot = Cors[[pp]])
}))
colnames(R2sSEs) = c("R²", "Delta method\nSE")
CI = R2sSEs[, "R²"] + t(sapply(names(phenId1R2), function(pp) R2sSEs[pp, "Delta method\nSE"]*Quants))
CI[,2] = sapply(CI[,2], min, 1)
colnames(CI) = c("2,5%", "97,5%")
R2sSEsJN = t(sapply(names(phenId1R2), function(pp){
    RsquaredSE(MSEsReal[pp], margVars[pp], SEMSE = MultiMSECV[[pp]]$multiMod["Bates", "SE"], 
               n = samSizes[[pp]], rhoBoot = CorsJN[[pp]])
}))
colnames(R2sSEsJN) = c("R²", "Delta method jackknife\nSE")
R2sSEsJN = cbind(R2sSEsJN, "P-value" = pnorm(R2sSEsJN[, "R²"]/R2sSEsJN[, "Delta method jackknife\nSE"], lower.tail = FALSE))
CIjn = R2sSEsJN[, "R²"] + t(sapply(names(phenId1R2), function(pp) R2sSEsJN[pp, "Delta method jackknife\nSE"]*Quants))
CIjn[,2] = sapply(CIjn[,2], min, 1)
colnames(CIjn) = c("2,5%", "97,5%")
CIboot = R2sSEs[, "R²"] + outer(bootSEsBras, Quants)
colnames(CIboot) = c("2,5%", "97,5%")
R2sSEsci = cbind("R²" = R2sSEs[, "R²"],"Delta method\nSE" = R2sSEsJN[, "Delta method jackknife\nSE"], "Delta method P-value" =  R2sSEsJN[, "P-value"], CIjn, "Bootstrap SE" = bootSEsBras, "Bootstrap P-value" = pnorm(R2sSEsJN[, "R²"]/bootSEsBras, lower.tail = FALSE), CIboot)
```

```{r bootDfiffBrassica}
bootDiffReps = 50
if(!file.exists(bootDiffBrasFile <- "Results/bootDiffBras.RData")){
    bootDiffBras = mclapply(mc.cores = nCores, seq_len(bootDiffReps), function(j){
        idBoot = sample(nrow(rlogBras1), replace = TRUE)
        sapply(phenId1R2, function(phen){
            dat = list("x" = rlogBras1[idBoot,], "y" = phenData1[idBoot,phen])
            dat$y = dat$y[id <- !is.na(dat$y)];dat$x = dat$x[id,]
            #Use top 5000 features
            spearCors = abs(apply(dat$x, 2, cor, dat$y, use ="pairwise.complete.obs", method = "spearman"))
            dat$x = dat$x[,spearCors >= sort(spearCors, decreasing = TRUE)[topFeats]]
            multiMod = nestedCVglmnet(dat, nOuterFolds, cvSplits = cvSplitsReal, alpha = alpha)
            c("MSE" = multiMod["Bates", "MSEhat"], "margVar" = var(dat$y))
        })
    })
    save(bootDiffBras, file = bootDiffBrasFile)
} else load(bootDiffBrasFile)
```

```{r realDataZeaMays}
#Brassica napus
load("R2data/Cruz2020Data.RData")
phenId1R2zm = c("Blade_16_length", "Blade_16_width", "Husk_leaf_length", "Ear_length", "Plant_height")
names(phenId1R2zm) = phenId1R2zm
#Choose some phenotypes with high and some with low performance
id = !duplicated(CruzPheno$plant_id)
CruzPheno = CruzPheno[id ,][rownames(CruzRlog),]
colnames(CruzPheno)[5:9] = phenId1R2zm
topFeats = 5e3; cvSplitsReal = 1e2; bootRepsReal = 50
if(!file.exists(MultiMSEcvFileZM <- "Results/MultiMSECVr2ZM.RData")){
    MultiMSECVzm = lapply(phenId1R2zm, function(phen){
        dat = list("x" = CruzRlog, "y" = CruzPheno[,phen])
        dat$y = dat$y[id <- !is.na(dat$y)];dat$x = dat$x[id,]
        #Use top 5000 features
        relExpr = colSums(dat$x)
        dat$x = dat$x[,relExpr >= sort(relExpr, decreasing = TRUE)[topFeats]]
        multiMod = nestedCVglmnet(dat, nOuterFolds, alpha = alpha, cvSplits = cvSplitsReal)
        jackRes = vapply(FUN.VALUE = double(2), seq_along(dat$y), function(idOut){
              dat$y = dat$y[-idOut];dat$x=dat$x[-idOut,]
              MSE = mean(unlist(singleCVglmnet(dat, nOuterFolds, cvSplits = cvSplitsReal, alpha = alpha)))
              c("MSE" = MSE, "margVar" = var(dat$y))
        })
        bootRes = vapply(FUN.VALUE = double(2), seq_len(bootRepsReal), function(cvs){
              id = sample(seq_along(dat$y), replace = TRUE)
              dat$y = dat$y[id];dat$x=dat$x[id,]
              MSE = mean(unlist(singleCVglmnet(dat, nOuterFolds, cvSplits = cvSplitsReal, alpha = alpha)))
              c("MSE" = MSE, "margVar" = var(dat$y))
        })
        list("multiMod" = multiMod, "bootRes" = bootRes, "jackRes" = jackRes)
    })
    save(MultiMSECVzm, file = MultiMSEcvFileZM)
} else load(MultiMSEcvFileZM)
margVarsZM = sapply(phenId1R2zm, function(vv) {var(CruzPheno[[vv]], na.rm = TRUE)})
MSEsRealZM = sapply(names(phenId1R2zm), function(x) MultiMSECVzm[[x]]$multiMod["Bates", "MSEhat"])
samSizesZM = sapply(phenId1R2zm, function(pp){sum(!is.na(CruzPheno[[pp]]))})
CorsZM = sapply(names(phenId1R2zm), function(pp){cor(MultiMSECVzm[[pp]]$bootRes["MSE", ], MultiMSECVzm[[pp]]$bootRes["margVar", ])})
CorsZMjn = sapply(names(phenId1R2zm), function(pp){cor(MultiMSECVzm[[pp]]$jackRes["MSE", ], MultiMSECVzm[[pp]]$jackRes["margVar", ])})
bootSEsBrasZM = sapply(names(phenId1R2zm), function(pp){sd(MultiMSECVzm[[pp]]$bootRes["MSE", ]/MultiMSECVzm[[pp]]$bootRes["margVar", ])})
R2sSEsZM = t(sapply(names(phenId1R2zm), function(pp){
    RsquaredSE(MSEsRealZM[pp], margVarsZM[pp], SEMSE = MultiMSECVzm[[pp]]$multiMod["Bates", "SE"], 
               n = samSizesZM[[pp]], rhoBoot = CorsZMjn[[pp]])
}))
colnames(R2sSEsZM) = c("R²", "Delta method\nSE")
R2sSEsZM = cbind(R2sSEsZM, "P-value" = pnorm(R2sSEsZM[, "R²"]/R2sSEsZM[, "Delta method\nSE"], lower.tail = FALSE))
CI = R2sSEsZM[, "R²"] + t(sapply(names(phenId1R2zm), function(pp) R2sSEsZM[pp, "Delta method\nSE"]*Quants))
CI[,2] = sapply(CI[,2], min, 1)
colnames(CI) = c("2,5%", "97,5%")
CIboot = R2sSEsZM[, "R²"] + outer(bootSEsBrasZM, Quants)
colnames(CIboot) = c("2,5%", "97,5%")
CIboot[,2] = sapply(CIboot[,2], min, 1)
R2sSEsciZM = cbind(R2sSEsZM, CI, "Bootstrap SE" = bootSEsBrasZM, "Bootstrap P-value" = pnorm(R2sSEsZM[, "R²"]/bootSEsBrasZM, lower.tail = FALSE), CIboot)
```

```{r seR2, results = "asis", include = FALSE}
#Brassica napus
R2sSEsciCop = R2sSEsci
rownames(R2sSEsciCop) = gsub("_", " ", rownames(R2sSEsciCop))
colnames(R2sSEsciCop)[1] = "R²"
nDigits = c(NA, 2, 2, 1, 2, 2, 2, 1, 2, 2)
R2sSEsciCop[, !grepl(colnames(R2sSEsciCop), pattern =  "P-value")] = apply(R2sSEsciCop[, !grepl(colnames(R2sSEsciCop), pattern =  "P-value")], 1:2, round, digits = 2)
modPval = function(pval, minP = 1e-4){if(pval < minP) "< 0.0001" else as.character(round(pval, 2))}
R2sSEsciCop[, grep("P-value", colnames(R2sSEsciCop))] = apply(R2sSEsciCop[, grep("P-value", colnames(R2sSEsciCop))],2, function(x) sapply(x, modPval))
#display = c("s", "f", "f", "e", rep("f", 3), "e", "f", "f")
print(xtable(R2sSEsciCop, digits = nDigits, align = "l|ccccccccc", caption = "\\label{tab:R2se}Estimated \\rsq, delta method and nonparametric bootstrap standard error (SE), one-sided p-value and lower and upper bound of the 95\\% confidence interval for 5 \\textit{Brassica napus} phenotypes."), comment = FALSE)
#Zea mays
R2sSEsciZMCop = R2sSEsciZM
rownames(R2sSEsciZMCop) = gsub("_", " ", rownames(R2sSEsciZMCop))
colnames(R2sSEsciZMCop)[1] = "R²"
R2sSEsciZMCop[, !grepl(colnames(R2sSEsciZMCop), pattern =  "P-value")] = apply(R2sSEsciZMCop[, !grepl(colnames(R2sSEsciZMCop), pattern =  "P-value")], 1:2, round, digits = 2)
R2sSEsciZMCop[, grep("P-value", colnames(R2sSEsciZMCop))] = apply(R2sSEsciZMCop[, grep("P-value", colnames(R2sSEsciCop))],
                                                                  2, function(x) sapply(x, modPval))
print(xtable(R2sSEsciZMCop, digits = nDigits, align = "l|ccccccccc", caption = "\\label{tab:R2seZM}Estimated \\rsq, delta method and nonparametric bootstrap standard error (SE), one-sided p-value between brackets and lower and upper bound of the 95\\% confidence interval for 5 \\textit{Zea mays} phenotypes."), comment = FALSE)
```

```{r diffProcess, results="asis", include = FALSE}
sepMSE = lapply(phenId1R2, function(phen){
    MSE = sapply(bootDiffBras, function(x){
        x["MSE", phen]
    })
    margVar = sapply(bootDiffBras, function(x){
        x["margVar", phen]
    })
    cbind("MSE" = MSE, "margVar" = margVar, "R2" = 1-MSE/margVar)
})
mseMat = sapply(sepMSE, function(x) x[, "MSE"])
margVarMat = sapply(sepMSE, function(x) x[, "margVar"])
r2Mat = sapply(sepMSE, function(x) x[, "R2"])
corMatR2 = cor(r2Mat)
varSumMat = outer(R2sSEs[,"Delta method\nSE"]^2, R2sSEs[,"Delta method\nSE"]^2, "+")
covSumMat = outer(R2sSEs[,"Delta method\nSE"], R2sSEs[,"Delta method\nSE"], "*")
finalVarMat = varSumMat - 2*covSumMat*corMatR2
testDiffBN = outer(names(phenId1R2), names(phenId1R2), FUN = function(x, y){ 
    (R2sSEsci[x,"R²"]-R2sSEsci[y,"R²"])
})
testDiffBNStand = testDiffBN/sqrt(finalVarMat)
testDiffBNpVal = apply(testDiffBNStand, c(1,2), function(x){
    pnorm(x, lower.tail = x <0)*2
})
testDiffBNpVal[upper.tri(testDiffBNpVal)] = diag(testDiffBNpVal) = testDiffBNStand[upper.tri(testDiffBNStand)] = diag(testDiffBNStand) = NA
rownames(testDiffBNStand) = gsub("_", " ", rownames(testDiffBNStand))
colnames(testDiffBNStand) = gsub("_", " ", colnames(testDiffBNStand))
testDiffBNStand = round(testDiffBNStand, 2)
#Add p-values
testDiffBNStandP = matrix(gsub("NA \\(NA\\)", "", paste0(testDiffBNStand, " (", signif(testDiffBNpVal, 2), ")")), nrow(testDiffBNStand), ncol(testDiffBNStand), dimnames = dimnames(testDiffBNStand))
print(xtable(testDiffBNStandP[-1,-ncol(testDiffBNStand)], align = "l|cccc", caption = "\\label{tab:R2diffZ}Z-statistic for difference in \\rsq between columns and rows \\textit{Brassica napus} phenotypes, with corresponding p-value calculated using the delta method SE between brackets. For instance, the top left entry is the total branch count \\rsq minus leaf 8 width \\rsq, divided by a standard error estimate for this difference."), comment = FALSE)
```

```{r bootstrapSEdiff, results="asis", eval = FALSE}
bootDiffSE = sapply(names(phenId1R2), function(x){
    sapply(names(phenId1R2), function(y){ 
        sd(r2Mat[,x]-r2Mat[,y])
    })
})
bootStand = testDiffBN/bootDiffSE
bootPercP = sapply(names(phenId1R2), function(x) {
    sapply(names(phenId1R2), function(y){ 
        Pval = mean((R2sSEsci[x,"R²"]-R2sSEsci[y,"R²"]) < (r2Mat[,x]-r2Mat[,y] - mean(r2Mat[,x]-r2Mat[,y])))
        #Assumes the alternative distribution is just a shifted null
        min(Pval, 1-Pval)*2
    })
})
bootPercP[upper.tri(bootPercP)] = diag(bootPercP) = NA
rownames(bootPercP) = gsub("_", " ", rownames(bootPercP))
colnames(bootPercP) = gsub("_", " ", colnames(bootPercP))
print(xtable(bootPercP[-1,-ncol(bootPercP)], digits = 2, align = "l|cccc", caption = "\\label{tab:R2diffPboot}Bootstrap p-value for difference in \\rsq between columns and rows \\textit{Brassica napus} phenotypes using 200 bootstrap replicates. For instance, the top left entry is the p-value for the difference between leaf 8 width and total branch count \\rsq."), comment = FALSE)
```

# Simulation study: exhaustive results

## One-dimensional scenario

### True values

```{r trueR2, results = 'asis'}
trueR2sAlltrue = Reduce(f = rbind, lapply(seq_along(sweepProcess), function(i){
    cbind(gridSweep[i,], 'R2' = 1-sweepProcess[[i]][[1]]$true["trueMSE"]/sweepProcess[[i]][[1]]$true["trueMargVar"])
}))
R2matagg = aggregate(R2 ~ betas + samSize, data = trueR2sAlltrue, FUN = mean)
R2castTrue = acast(R2matagg, betas~ samSize, value.var = "R2")
names(dimnames(R2castTrue)) <- c("Effect size", "Sample size")
print.xtableFtable(xtableFtable(ftable(round(R2castTrue,3), method = "non.compact"), digits = 3, caption = "Monte-Carlo approximated true $R^2$ values for the one-dimensional scenario for different sample sizes (columns) and effect sizes $\\beta$ (rows).\\label{tab:trueR2}"), comment = FALSE)
```

```{r trueSE, results = 'asis', include = FALSE}
trueR2sAll = Reduce(f = rbind, lapply(seq_along(sweepProcess), function(i){
    cbind(gridSweep[i,], 'R2' = sapply(sweepProcess[[i]], function(x){
        n = gridSweep[i,"samSize"]
        1-x[['MSEhat']]/x[['margVar']]
    }))
}))
trueSEsAll = cbind(gridSweep, 'SER2' = sapply(seq_along(sweepProcess), function(i){sweepProcess[[i]][[1]]$ses["oracleSE"]}))
R2mataggSE = trueSEsAll[with(trueSEsAll, bootReps == 500 & cvSplitsSweep == 200),]
R2cast = acast(R2mataggSE, betas~ samSize, value.var = "SER2")
names(dimnames(R2cast)) <- c("Effect size", "Sample size")
print.xtableFtable(xtableFtable(ftable(round(R2cast,3), method = "non.compact"), digits = 3, caption = "Monte-Carlo approximated true standard errors (SE) of the $R^2$ estimated through cross-validation for the one-dimensional scenario for different sample sizes (columns) and effect sizes $\\beta$ (rows) for 200 cross-validation splits.\\label{tab:trueSER2}"), comment = FALSE)
```

```{r trueSEfig, fig.height = 3.5, fig.cap = "Monte-Carlo approximated true standard errors (SE) of the \\hrsq (y-axis) estimated through cross-validation for the one-dimensional scenario for different sample sizes (x-axis), effect sizes $\\beta$ (top panels) and number of cross-validation splits (line type). Especially at weak effect strengths, repeating the cross-validation split reduces the standard error.\\label{fig:trueSER2}"}
ggplot(data = trueSEsAll[trueSEsAll$bootReps==500, ], mapping = aes_string(x = "samSize", y = "SER2", linetype = "factor(cvSplitsSweep)")) + geom_line() + scale_linetype_manual(values = linetypes) + guides(linetype = guide_legend("Number of cross-validation splits")) + 
    facet_grid(~betas) + xlab("Sample size") + ylab(bquote("Standard error of the "*R^2*" estimator"))
```

```{r trueSEboot, results = 'asis', include = FALSE}
trueR2sAllboot = Reduce(f = rbind, lapply(seq_along(sweepBootProcess), function(i){ 
    cbind(gridSweepBoot[i,], 'R2' = sapply(sweepBootProcess[[i]], function(x){
        n = gridSweepBoot[i,"samSize"]
        1-x[['MSEhat']]/x[['margVar']]
    }))
}))
trueSEsAllboot = cbind(gridSweepBoot, "SER2" = sapply(seq_along(sweepBootProcess), function(i){
    sweepBootProcess[[i]][[1]]$ses["oracleSE"]
}))
R2mataggBoot = trueSEsAllboot[with(trueSEsAllboot, bootReps == 200 & bootRepsOuter == 50),]
R2cast = acast(R2mataggBoot, betas ~ samSize, value.var = "SER2")
names(dimnames(R2cast)) <- c("Effect size", "Sample size")
print.xtableFtable(xtableFtable(ftable(round(R2cast,3), method = "non.compact"), digits = 3, caption = "Monte-Carlo approximated true standard erros (SE) of the $R^2$ estimated through the .632 bootstrap for the one-dimensional scenario for different sample sizes (columns) and effect sizes $\\beta$ (rows) for 200 inner bootstrap instances.\\label{tab:trueSER2boot}"), comment = FALSE)
```

```{r trueSEfigBoot, fig.cap = "Monte-Carlo approximated true standard errors (SE) of the \\hrsq estimated through the .632 bootstrap (y-axis) for the one-dimensional scenario for different sample sizes (x-axis), effect sizes $\\beta$ (top panels) and number of .632 bootstraps (line type). \\label{fig:trueSER2boot}", fig.height = 3.5}
ggplot(data = trueSEsAllboot[trueSEsAllboot$bootRepsOuter==10, ], mapping = aes_string(x = "samSize", y = "SER2", linetype = "factor(bootReps)")) + geom_line() + guides(linetype = guide_legend("Number of .632 bootstraps")) + 
    facet_grid(~betas) + xlab("Sample size") + ylab(bquote("Standard error of the "*R^2*" estimator"))
```

```{r compareSEs, fig.cap = "\\label{fig:seMSE}Approximated true standard errors of the \\hrsq (y-axis) in the one-dimensional scenario for cross-validation and .632 bootstrap estimates (colour) for different sample sizes (x-axis) and signal strengths (top panels) over 1,000 Monte-Carlo instances. The number of cross-validation splits was 25, and the number of .632 bootstraps was 200; with these settings, the cross-validation takes about twice as long as the .632 bootstrap to estimate the \\rsq and its SE.", fig.height = 4}
trueSEcv = cbind("trueSE" = sapply(seq_along(sweepProcess), function(x){ 
    sweepProcess[[x]][[1]]$ses["oracleSE"]
}), gridSweep)
trueSEboot = cbind("trueSE" = sapply(seq_along(sweepBootProcess), function(x){
    sweepBootProcess[[x]][[1]]$ses["oracleSE"]
}), gridSweepBoot)
trueSEcv = trueSEcv[with(trueSEcv, samSize %in% unique(trueSEboot$samSize) & betas %in% unique(trueSEboot$betas) & cvSplitsSweep == 25 & bootReps == 10),]
trueSEcv$Data_splitting_algorithm = "Cross-validation"
trueSEboot$Data_splitting_algorithm = ".632 Bootstrap"
trueSEboot = trueSEboot[with(trueSEboot, bootReps==200 & bootRepsOuter == 10), ]
namesKeep = c("trueSE", "samSize", "betas", "Data_splitting_algorithm") 
trueMSEmerge = rbind(trueSEcv[, namesKeep], trueSEboot[, namesKeep])
ggplot(data = trueMSEmerge, aes(x = samSize, y = trueSE, colour = Data_splitting_algorithm)) + geom_point() + facet_grid(~betas) +  ylab(bquote("True standard error of the "*R^2)) + xlab("Sample size") + scale_x_continuous(breaks = unique(trueSEboot$samSize)) + theme(axis.text.x = element_text(angle = 60))
```

\clearpage

```{r r2average, include = FALSE}
nSimAv = 1e3 
gridAv = expand.grid('samSize' = samSize[-2], 'betas' = betas)
unFolds <- seq_len(nOuterFolds)
if(!file.exists(avR2File <- "Results/avR2.RData")){
    avR2s = mclapply(mc.cores = nCores, seq_len(nrow(gridAv)), function(j){
        vapply(integer(nSimAv), FUN.VALUE = double(3), function(i){
            nAv = gridAv[j, "samSize"]
            foldsAv = sample(rep(unFolds, length.out = nAv))
            trainDat = genDat(nAv, 1, betas = gridAv[j, "betas"])
            R2s = vapply(unFolds, FUN.VALUE = double(3),function(uf){
                    idTrain = foldsAv!=uf
                    predTest = predLin(trainDat$x[idTrain,1], trainDat$y[idTrain], trainDat$x[!idTrain,1])
                    MSE = mean((predTest-trainDat$y[!idTrain])^2)
                    MST = var(trainDat$y[idTrain])*(sum(idTrain)+1)/sum(idTrain)
                    MSTtest = var(trainDat$y[!idTrain])
                    c("MSE" = MSE, "R2" = 1-MSE/MST, "R2test" = 1-MSE/MSTtest)
                })
            MSTtot = var(trainDat$y)*(nAv+1)/nAv
            c("Pooling R2" = 1-mean(R2s["MSE",])/MSTtot, "Averaging R2\ntraining MST" = mean(R2s[ "R2",]), 
              "Averaging R2\ntest MST" = mean(R2s[ "R2test",]))
        })
    })
    save(avR2s, file = avR2File)
} else load(avR2File)
moltAvR2 = melt(id.vars = c("samSize", "betas"), Reduce(f = rbind, lapply(seq_along(avR2s), function(x) cbind(t(avR2s[[x]]), gridAv[x, ]))))
moltAvR2agg = aggregate(value ~ samSize + betas + variable, FUN = mean, data = moltAvR2)
ggplot(data = moltAvR2, aes(y = value, col = variable, x = variable)) + geom_boxplot() +
    stat_boxplot(geom ='errorbar', width = 0.5) + 
    facet_grid(samSize ~ betas, scale = "free_y") + coord_cartesian(ylim = c(-1, max(moltAvR2$value))) +
    geom_point(data = moltAvR2agg, aes(x = variable, y = value), shape = 5) +
    geom_hline(data = R2matagg[R2matagg$samSize %in% unique(gridAv$samSize),], 
               aes(yintercept = R2), linetype = "dotted") +
    scale_colour_discrete(name = "Estimation method") +
    theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) +
    ylab("R² estimate") + xlab("")
ggsave("Graphs/estR2.pdf", height = 5.3, width = 7.5)
```

\clearpage

### Bias

```{r bootCVEstimationBias, fig.cap = "Estimated MSE minus approximated true MSE averaged over 1,000 Monte-Carlo instances (y-axis) for the one-dimensional scenario for cross-validation with 200 CV splits (left) and for the .632 bootstrap with 200 inner bootstrap instances (right) as a function of sample size (x-axis) and signal strength (side panels). The horizontal dotted line at 0 indicates no bias. Bootstrap .632 estimation clearly has a downward bias in MSE estimation, which decreases with increasing sample size, whereas cross-validation with bias correction as proposed by \\textcite{Bates2023} is unbiased.\\label{fig:biasMSE}", fig.width = 4.2}
biasBoot = cbind("biasMSE" = sapply(sweepBootProcess, function(x){ 
    mean(sapply(x, function(y){
        y$MSEhat-y$true["trueMSE"]
    })) 
}), gridSweepBoot)
biasBootAgg = aggregate(biasMSE ~ samSize + betas, biasBoot[biasBoot$bootReps==200, ], FUN = mean)
biasBootAgg$Resampling_method = "Bootstrap"
biasCV = cbind("biasMSE" = sapply(sweepProcess, function(x){
    mean(sapply(x, function(y){
        y$MSEhat-y$true["trueMSE"]
    }))
}), gridSweep)
biasCVagg = aggregate(biasMSE ~ samSize + betas, biasCV[biasCV$cvSplitsSweep==200, ], FUN = mean)
biasCVagg$Resampling_method = "Cross-validation"
biasAllAgg = rbind(biasCVagg, biasBootAgg)
biasAllAgg$Resampling_method = factor(biasAllAgg$Resampling_method, levels = c("Cross-validation", "Bootstrap"), ordered = TRUE)
ggplot(data = biasAllAgg, aes_string(y = "biasMSE", x = "samSize")) + geom_line() + facet_grid(betas ~ Resampling_method) + xlab("Sample size") + ylab(bquote('Bias of MSE estimation')) + geom_hline(yintercept = 0, linetype = "dotted") 
```

```{r biasR2, fig.cap = "Estimation error of the \\rsq estimation (y-axis) through cross-validation and bootstrap (top panels) in the one-dimensional scenario over 1,000 Monte-Carlo instances as a function of sample size (x-axis) and signal strength (side panels) for 200 cross-validation splits and 200 .632 bootstrap instances. Bias decreases with growing sample size and for .632 bootstrap with growing effect size. \\label{fig:biasR2Uni}", fig.width = 4.2}
biasProcR2 = cbind("biasR2" = sapply(seq_along(sweepProcess), function(x){
    biasR2 = sapply(sweepProcess[[x]], function(y){
        estR2 = 1-y$MSEhat/y$margVar
        trueR2 = 1-y$true["trueMSE"]/y$true["trueMargVar"]
        estR2 - trueR2
    })
    mean(biasR2)
}), gridSweep)
biasCVagg = aggregate(biasR2 ~ samSize + betas, biasProcR2[biasProcR2$cvSplitsSweep == 200,], FUN = mean)
biasCVagg$Resampling_method = "Cross-validation"
biasProcR2boot = cbind("biasR2" = sapply(seq_along(sweepBootProcess), function(x){
    biasR2 = sapply(sweepBootProcess[[x]], function(y){
        estR2 = 1-y$MSEhat/y$margVar
        trueR2 = 1-y$true["trueMSE"]/y$true["trueMargVar"]
        estR2 - trueR2
    })
    mean(biasR2)
}), gridSweepBoot)
biasBootagg = aggregate(biasR2 ~ samSize + betas, biasProcR2boot[biasProcR2boot$bootReps == 200,], FUN = mean)
biasBootagg$Resampling_method = "Bootstrap"
biasAllAgg = rbind(biasCVagg, biasBootagg) 
biasAllAgg$Resampling_method = factor(biasAllAgg$Resampling_method, levels = c("Cross-validation", "Bootstrap"), ordered = TRUE)
ggplot(data = biasAllAgg, aes_string(y = "biasR2", x = "samSize")) + geom_line() + facet_grid(betas ~ Resampling_method, scale = "free_y") + guides(linetype = guide_legend("Number of cross-validation splits")) + 
    xlab("Sample size") + ylab(bquote('Bias of the '*R^2*' estimation')) + scale_linetype_manual(values = linetypes) +  scale_x_continuous(breaks = samSize) + theme(axis.text.x = element_text(angle=60)) + geom_hline(yintercept = 0, linetype = "dotted")
```

\clearpage

The unbiasedness of the analytical estimator for the MST in equation \eqref{eq:MST} in the main text is illustrated in a separate simulation experiment. Data $\mb Y$ are drawn from a normal distribution with mean 0 and variance $\sigma^2 = 2.25$ with a sample size of 10. Three different approaches are used to estimate the out-of-sample MST: an independent test set, cross-validation and the analytical MST from \eqref{eq:MST}. In the first case, an independent test set of size 10 is drawn in the same way as the data the model is trained on, and the average squared difference between the mean of the original dataset and the observations of the test set is used to estimate MST. For the cross-validation case, leave-one-out CV is used to estimate the MST. To eliminate bias from difference in dataset size, the total sample size for the cross-validation was 11, leading to training folds of size 10. Boxplots of the three estimates over 100,000 Monte-Carlo instances are shown in \fref{fig:biasMST}, demonstrating the equivalence of the three approaches, as well as the necessity of the inflation factor $\frac{n+1}{n}$ in \eqref{eq:MST}. Evidently, the analytical MST from expression \eqref{eq:MST} is the fastest and simplest option. 

```{r biasMST, fig.cap = "Boxplots of MST estimated on an independent test set, through leave-one-out cross-validation and analytically (equation \\eqref{eq:MST} in the main text) for a sample size of 10, for 100,000 Monte-Carlo instances. The red horizontal line indicates the variance of the outcome Var(Y); the blue line indicates Var(Y)*(n+1)/n, the true MST.\\label{fig:biasMST}", fig.width = 6.5, fig.height = 4.5}
nMST = 10
sdMST = 1.5
MSTsim = sapply(integer(1e5), function(j){
    yTest = rnorm(nMST, sd = sdMST)
    y = rnorm(nMST, sd = sdMST)
    meanY = mean(y)
    MSTtest = mean((meanY-yTest)^2)
    yCV = rnorm(no <- nMST*(nOuterFolds+1)/nOuterFolds, sd = sdMST)
    foldid = sample(rep(seq_len(nOuterFolds+1), length.out = no))
    MSTcv = mean(sapply(seq_len(nOuterFolds+1), function(i){
        meanY = mean(yCV[foldid!=i])
        mean((meanY-yCV[foldid==i])^2)  
    }))
    c("Test MST" = MSTtest, "Cross-validation MST" = MSTcv, "Analytical MST" = var(y)*(nMST+1)/nMST)
})
boxplot(t(MSTsim))
points(pch = 5, 1:nrow(MSTsim), rowMeans(MSTsim))
abline(h = sdMST^2, col = "red")
abline(h = sdMST^2*(nMST+1)/nMST, col = "blue")
```

\clearpage

### Variance

#### The variance of the MSE
<!-- The estimation of the variance of the MSE is investigated in Figures \ref{fig:biasMSESE}-\ref{fig:biasMSESEboot}. -->

```{r varMSE, fig.cap = "Mean difference between the cross-validation Var(MSE) estimator by \\textcite{Bates2023} and approximated true variance of the MSE over 1,000 Monte-Carlo instances (y-axis) in the one-dimensional scenario as a function of  sample size (x-axis), number of cross-validation splits (top panels) and signal strength (side panels). The dotted line at zero indicates no bias. For sufficiently large sample sizes and number of cross-validation splits, the estimator of the variance is nearly unbiased.\\label{fig:biasMSESE}"}
biasProcMSESE = cbind(gridSweep, "biasSEMSE" = sapply(seq_along(sweepProcess), function(x){
    resMSE = sapply(sweepProcess[[x]], function(y){
        c("MSEhat" = y$MSEhat, "MSEsSE" = y$MSEsSE)
    })
    mean(resMSE["MSEsSE",]^2 - var(resMSE["MSEhat",]))
}))
ggplot(data = biasProcMSESE[biasProcMSESE$bootReps==500,], aes_string(y = "biasSEMSE", x = "samSize")) + geom_line() + facet_grid(betas ~ cvSplitsSweep, scale = "free_y") + xlab("Sample size") + ylab("Bias of the Var(MSE) estimation") + scale_x_continuous(breaks = samSize) + theme(axis.text.x = element_text(angle=60)) +
    geom_hline(yintercept = 0, linetype = "dotted")
```

```{r varMSEBoot, fig.cap = "Mean difference between the .632 bootstrap Var(MSE) estimator by \\textcite{Efron1997} and approximated true variance of the MSE over 1,000 Monte-Carlo instances (y-axis) in the one-dimensional scenario as a function of  sample size (x-axis), number of bootstraps (top panels) and signal strength (side panels). The dotted line at zero indicates no bias. The bias decreases with number of bootstrap samples and sample size.\\label{fig:biasMSESEboot}"}
biasProcMSESEboot = cbind(gridSweepBoot, "biasSEMSE" = sapply(seq_along(sweepBootProcess), function(x){
    resMSE = sapply(sweepBootProcess[[x]], function(y){
        c("MSEhat" = y$MSEhat, "MSEsSE" = y$MSEsSE)
    })
    mean(resMSE["MSEsSE",]^2 - var(resMSE["MSEhat",]), na.rm = TRUE)
}))
ggplot(data = biasProcMSESEboot[biasProcMSESEboot$bootRepsOuter==10,], aes_string(y = "biasSEMSE", x = "samSize")) + 
    geom_line() + facet_grid(betas ~ bootReps, scale = "free_y") + 
    xlab("Sample size") + ylab("Bias of the Var(MSE) estimation") + scale_x_continuous(breaks = samSize) + theme(axis.text.x = element_text(angle = 60)) + geom_hline(yintercept = 0, linetype = "dotted")
```

\clearpage

#### Cross-validation
<!-- Cross-validation results are shown in Figures \ref{fig:mseUni}-\ref{fig:zTest}. -->

```{r sweepProcBiasSEmse, fig.cap = "MSE of the standard error (SE) of the \\rsq (y-axis) for cross-validation in the one-dimensional scenario as a function of estimation method (colour), sample size (x-axis), number of bootstraps (top panels), signal strength (side panels) and number of cross-validation splits (linetype). The y-axis is on the log scale. The MSE of the SE estimation is seen to decrease with sample size and for the delta method SE also with the number of cross-validation splits. See \\fref{fig:OneDim} in the main text for the direction of the error. \\label{fig:mseUni}", fig.height = 5}
biasProcSE = Reduce(f = rbind, lapply(seq_along(sweepProcess), function(x){
    biasSE = sapply(sweepProcess[[x]], function(y){
        trueR2se = y$ses["oracleSE"]
        estR2se = y$ses[c("bootRhos", "bootRhosParam", "jnRhos", "bootSEs", "bootParamSEs")]
        (estR2se-trueR2se)^2
    })
    cbind("MSESE" = unname(rowMeans(biasSE)), "Method" = rownames(biasSE), gridSweep[x,])
}))
biasProcSE$Method = factor(biasProcSE$Method, levels = methodLevels, labels = methodLabels)
linetypes = c("solid", "dashed", "dotdash", "dotted"); names(linetypes) = cvSplitsSweep
ggplot(data = biasProcSE, aes_string(y = "MSESE", x = "samSize", colour = "Method", linetype = "factor(cvSplitsSweep)")) + geom_line() + facet_grid(betas ~ bootReps, scale = "free_y")+ guides(linetype = guide_legend("Number of cross-validation splits")) + 
    xlab("Sample size") + ylab(bquote('MSE of the estimated SE of the '*R^2)) + scale_linetype_manual(values = linetypes) + scale_colour_manual(values = methodColours[names(methodColours) %in% SEplot]) + scale_y_log10()  + scale_x_continuous(breaks = samSize) + theme(axis.text.x = element_text(angle=60))
#added value of extra cvsplits reaches plateau around 100 already  
```

```{r deeperLookUni, fig.width = 7, fig.cap = "Boxplots of estimated correlation $\\rho$ between MSE and MST estimators over 1,000 Monte-Carlo instances (y-axis) using different methods (colours) for cross-validation using 200 splits for different signal strengths (side panels) and sample sizes (top panels) in the one-dimensional scenario. 500 bootstraps were done for the bootstrap estimation of $\\rho$. The approximated true correlation is shown as dashed line, the dotted line at 0 is a visual aid. The nonparametric bootstrap provides the least biased estimator over all scenarios.\\label{fig:corEst}"}
oracleCors = sapply(rhosProc, function(i){
    unique(i[, "oracleRho"])
})
rhoList = lapply(rhosProc, function(x){
    x[, !colnames(x) %in% c("oracleRho", "cvRhos")]
}); names(rhoList) = seq_len(nrow(gridSweep))
oracleDf = data.frame("oracleCor" = oracleCors, gridSweep)
moltRhoList = melt(rhoList)
colnames(moltRhoList) = c("Rep", "Method", "Correlation", "L1") 
moltRhoList = cbind(moltRhoList, gridSweep[as.integer(moltRhoList$L1),])
moltRhoList$Method = factor(moltRhoList$Method, levels = methodLevels, labels = labNew <- gsub("\\)", "", gsub("Delta method SE \\(", "", methodLabels))) 
idd <- c(1,2,4)
coloursCor = methodColours; names(coloursCor)[idd] = levels(moltRhoList$Method)[idd]
ggplot(data = moltRhoList[with(moltRhoList, bootReps==bootRepsSweep[4] & cvSplitsSweep==cvSplitsSweep[4]),], aes_string(y = "Correlation", color = "Method")) + geom_boxplot() + ylab(bquote("Estimated correlation between MSE and MST estimators"))+
    facet_grid(betas~ samSize) + geom_hline(linetype ="dashed", data = oracleDf[with(oracleDf, bootReps==bootRepsSweep[1] & cvSplitsSweep==cvSplitsSweep[1]),], aes(yintercept = oracleCor)) + geom_hline(yintercept = 0, linetype = "dotted")+ 
    scale_colour_manual(values = coloursCor[levels(moltRhoList$Method) %in% names(coloursCor)[idd]]) +
    theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
rm(idd)
#In low dimensions, nonparametric bootstrap provides and excellent estimate of the correlation, with parametric bootstrap tending to overestimate it and cross-validation tending to underestimate
```

```{r plotwidthsweep, fig.cap = 'Average width of the 95\\% confidence intervals for \\rsq across 1,000 Monte-Carlo instances (y-axis) for cross-validation in the one-dimensional scenario for different sample sizes (x-axis), method (colour), signal strength (side panel) and number of bootstrap replicates (top panels) for 200 repeats of the cross-validation splits. The number of bootstraps has little effect on the confidence intervals of the methods based on the delta method SE.\\label{fig:sweepWidth}', fig.height = 6, fig.width = 7}
sweepSumW = cbind(gridSweep, r2cisweepWidthSum)
sweepSumMoltW = melt(sweepSumW, id.vars = names(gridSweep), value.name = "Width_of_confidence_interval", variable.name = 'Method')
sweepSumMoltW$betas = factor(sweepSumMoltW$betas)
sweepSumMoltW$Method = factor(sweepSumMoltW$Method, levels = methodLevels, labels = methodLabels)
ggplot(data = sweepSumMoltW[with(sweepSumMoltW, cvSplitsSweep==200 & Method %in% labels2plot),], aes(x = samSize, y = Width_of_confidence_interval, col = Method)) + geom_line() + facet_grid(betas~ bootReps, scale = "free_y") + xlab("Sample size") + 
    ylab(bquote("Width of the 95% confidence interval for "*R^2)) + scale_x_continuous(breaks = samSize) + 
    scale_colour_manual(values = methodColours[names(methodColours) %in% labels2plot]) + theme(axis.text.x = element_text(angle=60))
# Add plots of se vs obs, non-normality? Perhaps irrelevant
```

```{r zTest, fig.cap = "Type I error of approximate one-sided z-tests that \\rsq $\\leq$ 0 (y-axis) as a function of sample size (y-axis), number of bootstrap replicates (top panels) and repeats of the cross-validation split (side panels) for cross-validation in the one-dimensional scenario with effect size 0. All type I errors lie well below the significance level of 5\\% (see Table \\ref{tab:trueR2} for true \\rsq values).\\label{fig:zTest}", fig.height = 6}
typeIerrorPointSize = .8;dodgeTypeI = 3
#Evaluate one-sided approximate z-test
zTestEval = lapply(nullId <- seq_along(sweepProcess)[gridSweep[, "betas"]==0], function(i){
    sapply(sweepProcess[[i]], function(y){
        with(y, {
            R2hat = 1-MSEhat/margVar
            pnorm(R2hat/ses, lower.tail = FALSE)
        })
    })
})
#Calculate type I error
typeIerrorZ = cbind(gridSweep[nullId, ], t(sapply(zTestEval, function(x){
    rowMeans(x < sigLevel)
})))
typeIerrorZMolt = melt(typeIerrorZ, id.vars = colnames(gridSweep), variable.name = "Method", value.name = "Type_I_error")
typeIerrorZMolt$Method = factor(typeIerrorZMolt$Method, levels = methodLevels, labels = methodLabels)
ggplot(data = typeIerrorZMolt[typeIerrorZMolt$Method %in% labels2plot,], aes_string(x = "samSize", y = "Type_I_error", col = "Method", group = "Method")) + geom_point(size = typeIerrorPointSize, position = position_dodge(width = dodgeTypeI)) + facet_grid(cvSplitsSweep ~ bootReps) + xlab("Sample size")+ 
    scale_colour_manual(values = methodColours[names(methodColours) %in% intersect(typeIerrorZMolt$Method, labels2plot)]) + scale_x_continuous(breaks = samSize) + theme(axis.text.x = element_text(angle=60)) +ylab("Type I error")
```

\clearpage

#### The .632 bootstrap

```{r BootSweepCovProc}
bootSweepCI = lapply(seq_along(sweepBootProcess), function(i){
    lapply(sweepBootProcess[[i]], function(x){
        R2 = 1-x[['MSEhat']]/x[['margVar']]
        CI = R2 + outer(x[['ses']], Quants)
        CI = rbind(CI, x[["bootQuants"]])
        CI[, 2] = sapply(CI[, 2], min, 1)
        CI
    }) 
}) 
bootSweepNonCov = vapply(seq_along(sweepBootProcess), FUN.VALUE = array(TRUE, dim = c(numRow <- nrow(bootSweepCI[[1]][[1]]),2, sweepReps)), function(i){
    trueR2 = 1 - sweepBootProcess[[i]][[1]]$true[["trueMSE"]]/sweepBootProcess[[i]][[1]]$true[["trueMargVar"]]
    vapply(bootSweepCI[[i]], FUN.VALUE = matrix(TRUE, nrow(bootSweepCI[[i]][[1]]),2), function(CI){
        cbind("under" = trueR2 < CI[,1], "over" = trueR2 > CI[,2])
    })
})
r2cisweepCovBoot = !apply(bootSweepNonCov, c(1,3,4), any, na.rm = TRUE)
r2cisweepWidthBoot = vapply(seq_along(sweepBootProcess), FUN.VALUE = matrix(0, numRow, sweepReps), function(i){
    sapply(bootSweepCI[[i]], function(CI){
        apply(CI, 1, diff)
    })
})
r2cisweepCovSum = t(apply(r2cisweepCovBoot, c(1,3), mean, na.rm = TRUE));r2cisweepWidthSum = t(apply(r2cisweepWidthBoot, c(1,3), mean, na.rm = TRUE))
sweepSum = cbind(gridSweepBoot, r2cisweepCovSum)
sweepSumMoltBoot = melt(sweepSum, id.vars = names(gridSweepBoot), value.name = "Coverage", variable.name = 'Method')
sweepSumMoltBoot$betas = factor(sweepSumMoltBoot$betas)
sweepSumMoltBoot$Method = factor(sweepSumMoltBoot$Method, levels = methodLevels, labels = methodLabels)
labels2plotBoot = labels2plot
```

```{r sweepProcBiasSEboot, fig.cap = "Log10 of geometric mean of the ratios of estimated to the approximated true SE of the \\rsq over 1,000 Monte-Carlo instances (y-axis) in the one-dimensional scenario for the .632 bootstrap as a function of estimation method (colour), sample size (x-axis), number of inner .632 bootstraps for MSE estimation (top panels), signal strength (side panels) and number of outer bootstraps (linetype). The results are similar to the CV results in the top panel of \\fref{fig:OneDim}.\\label{fig:biasUniBoot}", fig.widht = 7, fig.height = 7}
linetypesBoot = c("solid", "dashed", "dotdash", "dotted"); names(linetypesBoot) = bootRepsSweep
biasProcSEboot = Reduce(f = rbind, lapply(seq_along(sweepBootProcess), function(x){
    biasSE = sapply(sweepBootProcess[[x]], function(y){
        trueR2se = y$ses["oracleSE"]
        estR2se = y$ses[c("bootRhos", "bootRhosParam", "jnRhos", "bootSEs", "bootParamSEs" )]
        estR2se/trueR2se 
    }) 
    cbind("BiasSE" = unname(rowMeans(log10(biasSE), na.rm = TRUE)), "Method" = rownames(biasSE), gridSweepBoot[x,])
}))
biasProcSEboot$Method = factor(biasProcSEboot$Method, levels = methodLevels, labels = methodLabels)
ggplot(data = biasProcSEboot, aes_string(y = "BiasSE", x = "samSize", colour = "Method", linetype = "factor(bootRepsOuter)")) + geom_line() + facet_grid(betas ~ bootReps, scale = "free_y")+ guides(linetype = guide_legend("Number of outer bootstrap repeats")) + 
    xlab("Sample size") + ylab(bquote('Log10 of the geometric mean of the ratio of estimated to the approximated true SE of the '*R^2)) + geom_hline(yintercept = 0, linetype ="dotted") + scale_linetype_manual(values = linetypesBoot) + 
    scale_colour_manual(values = methodColours[names(methodColours) %in% grep("SE", labels2plot, value = TRUE)]) + scale_x_continuous(breaks = samSize) + theme(axis.text.x = element_text(angle=60))
#added value of extra cvsplits reaches plateau around 100 already 
```

```{r sweepProcMSESEboot, fig.cap = "MSE of the estimated SE of the .632 bootstrap \\rsq (y-axis) as a function of estimation method (colour) in the one-dimensional scenario, sample size (x-axis), number of inner .632 bootstraps for MSE estimation (top panels), signal strength (side panels) and number of outer bootstraps (linetype). The y-axis is on the log scale. The MSE is seen to decrease with the sample size, and for the delta method SE, with the number of inner .632 bootstraps. \\label{fig:mseUniBoot}"}
biasProcSEboot = Reduce(f = rbind, lapply(seq_along(sweepBootProcess), function(x){
    biasSE = sapply(sweepBootProcess[[x]], function(y){
        trueR2se = y$ses["oracleSE"]
        estR2se = y$ses[c("bootRhos", "bootRhosParam", "jnRhos", "bootSEs", "bootParamSEs" )]
        (estR2se-trueR2se)^2 
    }) 
    cbind("BiasSE" = unname(rowMeans(biasSE, na.rm = TRUE)), "Method" = rownames(biasSE), gridSweepBoot[x,])
}))
biasProcSEboot$Method = factor(biasProcSEboot$Method, levels = methodLevels, labels = methodLabels)
ggplot(data = biasProcSEboot, aes_string(y = "BiasSE", x = "samSize", colour = "Method", linetype = "factor(bootRepsOuter)")) + geom_line() + facet_grid(betas ~ bootReps, scale = "free_y")+ guides(linetype = guide_legend("Number of outer bootstrap repeats")) + xlab("Sample size") + ylab(bquote('MSE of estimated SE of the '*R^2)) + scale_linetype_manual(values = linetypesBoot) + scale_y_log10() +
    scale_colour_manual(values = methodColours[names(methodColours) %in% grep("SE", labels2plot, value = TRUE)]) + scale_x_continuous(breaks = samSize) + theme(axis.text.x = element_text(angle=60))
```

```{r deeperLookUniBoot, fig.width = 8,fig.cap = "Boxplots of estimated correlation $\\rho$ between MSE and MST estimators using different methods over 1,000 Monte-Carlo instances (colours) for .632 bootstrap for different signal strengths (side panels) and sample sizes (top panels) in the one-dimensional scenario, with 500 outer bootstraps and 200 inner bootstraps. The approximated true correlation is shown as dashed line, the dotted line at 0 is a visual aid. The nonparametric bootstrap provides the least biased estimator over all scenarios.\\label{fig:corEstBoot}"}
if(!file.exists(sweepRhosFileBoot <- 'simResults/sweepRhosFileBoot.RData')){
    load(bootSweepFile)
    rhosProcBoot = lapply(seq_len(nrow(gridSweepBoot)), function(i){
        obj = bootSweep[[i]]
        oracleRho = cor(t(sapply(obj$resList, function(x) c(x[["bootObj632ests"]][["procOb"]]["MSEhat",], x[["margVar"]]))))[1,2]
        out = t(sapply(obj$resList, function(xxx, oracleRho){
            with(xxx$bootObj632ests, {
            rhosMat = c("bootRhos" = cor(margVarBoot, unlist(procBoot)),
            "bootRhosParam" = cor(margVarBootParam, unlist(procBootParam)),
            "jnRhos" = cor(margVarJack, procJack),
            "oracleRho" = oracleRho)
        })
    }, oracleRho = oracleRho))
    })
    save(rhosProcBoot, file = sweepRhosFileBoot)
} else load(sweepRhosFileBoot)
oracleCors = sapply(rhosProcBoot, function(i){
    unique(i[, "oracleRho"])
})
rhoList = lapply(rhosProcBoot, function(x){
    x[, !colnames(x) %in% c("oracleRho", "cvRhos")]
}); names(rhoList) = seq_len(nrow(gridSweepBoot))
oracleDf = data.frame("oracleCor" = oracleCors, gridSweepBoot)
moltRhoList = melt(rhoList)
colnames(moltRhoList) = c("Rep", "Method", "Correlation", "L1")
moltRhoList = cbind(moltRhoList, gridSweepBoot[as.integer(moltRhoList$L1),])
moltRhoList$Method = factor(moltRhoList$Method, levels = methodLevels, labels = labNew <- gsub("\\)", "", gsub("Delta method SE \\(", "", methodLabels)))
idd <- c(1,2,4) 
coloursCor = methodColours; names(coloursCor)[idd] = levels(moltRhoList$Method)[idd]
ggplot(data = moltRhoList[with(moltRhoList, bootReps == bootRepsSweepBoot[3] & bootRepsOuter == bootRepsSweep[4]),], aes_string(y = "Correlation", color = "Method")) + geom_boxplot() + ylab(bquote("Estimated correlation between MSE and MST estimators"))+
    facet_grid(betas~ samSize) + geom_hline(linetype ="dashed", data = oracleDf[with(oracleDf, bootReps==bootRepsSweepBoot[1] & bootRepsOuter == bootRepsSweep[2]),], aes(yintercept = oracleCor)) + geom_hline(yintercept = 0, linetype = "dotted")+ 
    scale_colour_manual(values = coloursCor[levels(moltRhoList$Method) %in% names(coloursCor)[idd]]) +
    theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
rm(idd) 
```

```{r risweepCovBoot, fig.cap = 'Coverage of the 95\\% confidence intervals for \\rsq across 1,000 Monte-Carlo instances (y-axis) for the .632 bootstrap in the one-dimensional scenario for different sample sizes (x-axis), method (colour), signal strength (side panel) and number of inner .632 bootstrap replicates (top panels) for 500 repeats of the outer bootstrap. The results are similar to the CV case shown in \\fref{fig:OneDim}.\\label{fig:sweepCovBoot}'}
ggplot(data = sweepSumMoltBoot[with(sweepSumMoltBoot, bootRepsOuter==500 & Method %in% labels2plot),], aes(x = samSize, y = Coverage, col = Method, )) + geom_line() + facet_grid(betas~ bootReps, scale = "free_y") + xlab("Sample size") +
    geom_hline(yintercept = 1-sigLevel, linetype = 'dotted') + ylab(bquote("Coverage of the 95% confidence interval for "*R^2))+ 
    scale_colour_manual(values = methodColours[names(methodColours) %in% labels2plot])  + scale_x_continuous(breaks = samSize) + theme(axis.text.x = element_text(angle=60))
```

```{r plotwidthsweepBoot, fig.cap = 'Average width of the 95\\% confidence intervals for \\rsq across 1,000 Monte-Carlo instances (y-axis) for the .632 bootstrap in the one-dimensional scenario for different sample sizes (x-axis), method (colour), signal strength (side panel) and number of .632 bootstrap replicates (top panels) for 500 outer bootstrap repeats.\\label{fig:sweepWidthBoot}'}
sweepSumW = cbind(gridSweepBoot, r2cisweepWidthSum) 
sweepSumMoltW = melt(sweepSumW, id.vars = names(gridSweepBoot), value.name = "Width_of_confidence_interval", variable.name = 'Method')
sweepSumMoltW$betas = factor(sweepSumMoltW$betas)
sweepSumMoltW$Method = factor(sweepSumMoltW$Method, levels = methodLevels, labels = methodLabels)
ggplot(data = sweepSumMoltW[with(sweepSumMoltW, bootRepsOuter==500 & Method %in% labels2plot),], aes(x = samSize, y = Width_of_confidence_interval, col = Method)) + geom_line() + facet_grid(betas ~ bootReps, scale = "free_y") + xlab("Sample size") + ylab(bquote("Average width of the 95% confidence interval for "*R^2)) +
    scale_colour_manual(values = methodColours[names(methodColours)  %in% labels2plot]) + scale_x_continuous(breaks = samSize) + theme(axis.text.x = element_text(angle=60)) 
```

```{r zTestBoot, fig.height = 5, fig.cap = "Type I error of approximate one-sided z-tests that \\rsq $\\leq$ 0  (y-axis) as a function of sample size (y-axis), number of inner .632 bootstrap replicates (top panels) and outer bootstrap repeats (side panels) for the .632 bootstrap in the one-dimensional scenario with effect size 0. The horizontal dotted line indicates the significance level of 5\\%. See Table \\ref{tab:trueR2} for the true \\rsq values.\\label{fig:zTestBoot}"}
#Evaluate one-sided approximate z-test  
zTestEvalBoot = lapply(nullId <- seq_along(sweepBootProcess)[gridSweepBoot[, "betas"]==0], function(i){
    sapply(sweepBootProcess[[i]], function(y){
        with(y, {
            R2hat = 1-MSEhat/margVar
            pnorm(R2hat/ses, lower.tail = FALSE) 
        })
    })
})
#Calculate type I error
typeIerrorZ = cbind(gridSweepBoot[nullId, ], t(sapply(zTestEvalBoot, function(x){
    rowMeans(x < sigLevel)
}))) 
typeIerrorZMolt = melt(typeIerrorZ, id.vars = colnames(gridSweepBoot), variable.name = "Method", value.name = "Type_I_error")
typeIerrorZMolt$Method = factor(typeIerrorZMolt$Method, levels = methodLevels, labels = methodLabels)
ggplot(data = typeIerrorZMolt[typeIerrorZMolt$Method %in% labels2plot,], aes_string(x = "samSize", y = "Type_I_error", col = "Method")) + geom_point(size = typeIerrorPointSize, position = position_dodge(width = dodgeTypeI)) + facet_grid(bootRepsOuter ~ bootReps) + xlab("Sample size") + geom_hline(linetype = "dotted", yintercept = sigLevel)  +ylab("Type I error")+ 
    scale_colour_manual(values = methodColours[names(methodColours) %in% grep("oracle", ignore.case = TRUE, invert = TRUE, value = TRUE, unique(typeIerrorZMolt$Method))]) + scale_x_continuous(breaks = samSize) + theme(axis.text.x = element_text(angle=60))
```

\clearpage

## High-dimensional scenario

### True values

```{r r2ciSweepparametersweepHigh}
samSizeHigh = c(30, 50, 75, 100) 
betaBase = c(rep(1,p*fracSignal), rep(0, p*(1-fracSignal)))
betasHigh = outer(sigHigh <- c("0" = 0, "0.5" = 0.5, "1" = 1), betaBase)
bootRepsSweepHigh = c(10, 50, 100)
cvSplitsSweepHigh = c(5, 25, 100)
sweepRepsHigh = 1e2 
gridSweepHigh = expand.grid('samSize' = samSizeHigh, 'betas' = names(sigHigh), 
                            'bootReps' = bootRepsSweepHigh, 'cvSplits' = cvSplitsSweepHigh)
```

```{r HDsweepCI}
if(!file.exists(cvHDSweepFile <- "simResults/cvHdSweep.RData")){ 
  sweepHD = mclapply(mc.cores = nCores, seq_len(nrow(gridSweepHigh)), function(i){
    cat("Param combo", i, "\t")
    if(!file.exists(sweepFile <-
                               paste0("simResults/sweepFilesHD/", paste(gridSweepHigh[i,], collapse = '_')))){
        return(NULL)
    testData = genDat(n = nTest, p, betas = betasHigh[gridSweepHigh[i, 'betas'],])
    trueMSE = vapply(FUN.VALUE = double(1), integer(MCestReps), function(j){
      genDataAndgetTestMSE(gridSweepHigh[i, 'samSize'], p, betas = betasHigh[gridSweepHigh[i, 'betas'],], 
                           testDat = testData, highDim = TRUE, alpha = alpha)[[1]]
    })
    margVar = var(testData$y)
    resList = lapply(integer(sweepRepsHigh), function(j){
        id0 = seq_len(gridSweepHigh[i, 'samSize'])
        trainDat = genDat(gridSweepHigh[i, 'samSize'], p, betas = betasHigh[gridSweepHigh[i, 'betas'],])
        Fit = cv.glmnet(x = trainDat$x, y = trainDat$y, nfolds = nOuterFolds, alpha = alpha)
        Sigma = sqrt(Fit$cvm[Fit$index[2]]); Coef = coef(Fit)
        Mean = cbind(1,trainDat$x) %*% Coef
        bootRes = vapply(FUN.VALUE = double(2), seq_len(gridSweepHigh[i, 'bootReps']), function(cvs){
              id = sample(id0, replace = TRUE)
              trainDat$y = trainDat$y[id];trainDat$x=trainDat$x[id,]
              MSE = mean(unlist(singleCVglmnet(trainDat, nOuterFolds, cvSplits = gridSweepHigh[i, 'cvSplits'], alpha = alpha)))
              c("MSE" = MSE, "margVar" = var(trainDat$y))
            })
          bootResParam = vapply(FUN.VALUE = double(2), seq_len(gridSweepHigh[i, 'bootReps']), function(cvs){
              trainDat = bootstrap(x = trainDat$x, y = trainDat$y, paramBoot = TRUE, Mean = as.vector(Mean), Sigma = Sigma, id = id0)
              MSE = mean(unlist(singleCVglmnet(trainDat, nOuterFolds, cvSplits = gridSweepHigh[i, 'cvSplits'], alpha = alpha)))
              c("MSE" = MSE, "margVar" = var(trainDat$y))
            })
          singleModsBates = nestedCVglmnet(trainDat, nOuterFolds, cvSplits = gridSweepHigh[i, 'cvSplits'], alpha = alpha)
          jackKnifeEsts = t(sapply(id0, function(ii){
                trainDat$x = trainDat$x[-ii, ];trainDat$y = trainDat$y[-ii]
                MSE = mean(unlist(singleCVglmnet(trainDat, nOuterFolds, cvSplits = gridSweepHigh[i, 'cvSplits'], alpha = alpha)))
                c("MSE" = MSE, "margVar" = var(trainDat$y))
          }))
          list("singleModsBates" = singleModsBates, "bootRes" = bootRes, "bootResParam" = bootResParam, 
               "margVar" = var(trainDat$y), "jackKnifeEsts" = jackKnifeEsts)
         })
        out = list("resList" = resList, 'trueMSE' = trueMSE, "trueMargVar" = margVar)
        save(out, file = sweepFile)
        } else load(sweepFile)
        out
  })
  save(file = cvHDSweepFile, sweepHD)
} else load(cvHDSweepFile)  
```

```{r processSweepHD}
idHighExist = seq_len(nrow(gridSweepHigh)) 
if(!file.exists(sweepProcessFileHD <- 'simResults/sweepProcessFileHD.RData')){
    sweepProcessHD = lapply(seq_len(nrow(gridSweepHigh)), function(i){
        if(!(i %in% idHighExist)) return(NULL)
        n = gridSweepHigh[i, "samSize"]
        obj = sweepHD[[i]]
        oracleRho = cor(t(sapply(obj$resList, function(x) c(x[["singleModsBates"]]["Bates", "MSEhat"], x[["margVar"]]))))[1,2]
        rhoSEmat = lapply(obj$resList, function(xxx, oracleRho, oracleSE){
            with(xxx, {
                margVarOut = margVar*(n+1)/n
                rhosMat = cbind("bootRhos" = cor(t(bootRes))[2],#Indeed,  positive
                "bootRhosParam" = cor(t(bootResParam))[2],
                 "jnRhos" = cor(jackKnifeEsts)[2],
                "cvRhos" = singleModsBates["Bates","CovAndCor"],
                "oracleRho" = oracleRho)
                MSEs = singleModsBates["Bates", "MSEhat"]
                bootEstsR2 = 1-bootRes["MSE", ]/bootRes["margVar", ]*n/(n+1)
                bootEstsR2param = 1-bootResParam["MSE", ]/bootResParam["margVar", ]*n/(n+1)
                sesMat = c(apply(rhosMat, 2, function(rho){
                        RsquaredSE(MSE = singleModsBates["Bates", "MSEhat"], n = gridSweepHigh[i, 'samSize'], margVar = margVarOut,
                                   SEMSE = singleModsBates["Bates", "SE"], rhoBoot = rho)[2]
                }),
                "bootSEs" = sd(bootEstsR2),
                "bootParamSEs" = sd(bootEstsR2param),
                "oracleSE"  = oracleSE
                )
                bootQuantiles = quantile(bootEstsR2, quantsSweep)
                bootQuantilesParam = quantile(bootEstsR2param, quantsSweep)
                BCa = buildBCa(Rsq <- 1-MSEs/margVarOut, bootEstsR2, jackR2 <- 1-jackKnifeEsts[, "MSE"]/jackKnifeEsts[, "margVar"], sigLevel)
                BCaparam = buildBCa(Rsq, bootEstsR2param, jackR2, sigLevel)
                list("MSEhat" = MSEs, "margVar" = margVarOut, "ses" = sesMat, "rhosMat" = rhosMat,
                     bootQuants = rbind("boot" = bootQuantiles, "bootparam" = bootQuantilesParam, "BCa" = BCa, "BCaParam" = BCaparam))
            })
        }, oracleRho = oracleRho, oracleSE = oracleSE <- sd(sapply(obj$resList, function(x) x[["singleModsBates"]]["Bates", "MSEhat"]/ x[["margVar"]])))
        lapply(rhoSEmat, function(x) {
            x$ses = c(x$ses, "oracleSE" = oracleSE)
            x$true = c("trueMSE" = mean(obj[["trueMSE"]]), "trueMargVar" = obj[["trueMargVar"]])
        x})
        })
    save(sweepProcessHD, file = sweepProcessFileHD)
} else load(sweepProcessFileHD)
```

```{r r2ciSweepparametersweepHighBoot}
bootRepsSweepHighOuter = c(10, 30)
gridSweepHighBoot = expand.grid('samSize' = samSizeHigh, 'betas' = names(sigHigh), 
                                "bootReps" = bootRepsSweepBoot,
                            'bootRepsOuter' = bootRepsSweepHighOuter)
```

```{r HDsweepCIBoot}
if(!file.exists(bootHDSweepFile <- "simResults/bootHdSweepBoot.RData")){  
  sweepHDboot = mclapply(mc.cores = nCores, seq_len(nrow(gridSweepHighBoot)), function(i){
    cat("Param combo boot high", i, "\t")
    if(!file.exists(sweepFile <-
                               paste0("simResults/sweepFilesHDboot/", paste(gridSweepHighBoot[i,], collapse = '_'), ".RData"))){
        return(NULL)
    testData = genDat(n = nTest, p, betas = betasHigh[gridSweepHighBoot[i, 'betas'],])
    trueMSE = vapply(FUN.VALUE = double(1), integer(MCestReps), function(j){
      genDataAndgetTestMSE(gridSweepHighBoot[i, 'samSize'], p, betas = betasHigh[gridSweepHighBoot[i, 'betas'],], 
                           testDat = testData, highDim = TRUE, alpha = alpha)[[1]]
    })
    margVar = var(testData$y)
    resList = lapply(integer(sweepRepsHigh), function(j){
        id0 = seq_len(gridSweepHighBoot[i, 'samSize'])
        trainDat = genDat(gridSweepHighBoot[i, 'samSize'], p, betas = betasHigh[gridSweepHighBoot[i, 'betas'],])
        Fit = cv.glmnet(x = trainDat$x, y = trainDat$y, nfolds = nOuterFolds, alpha = alpha)
        Sigma = sqrt(Fit$cvm[Fit$index[2]]); Coef = coef(Fit)
        Mean = cbind(1,trainDat$x) %*% Coef
        FitParam = list("Mean" = Mean, "Sigma" = Sigma)
        bootObjOOB = fullBootGlmnet(trainDat, gridSweepHighBoot[i, 'bootReps'], alpha = alpha, "oob")
        bootObjOOBests = processOobGlmnet(bootObjOOB)
        bootObj632 = fullBootGlmnet(trainDat, bootReps = gridSweepHighBoot[i, 'bootReps'], alpha = alpha, bootMethod = "632", 
                              bootRepsOuter = gridSweepHighBoot[i, 'bootRepsOuter'], jackknife = TRUE, Fit = FitParam)
        bootObj632ests = process632Glmnet(bootObj632, oobObj = bootObjOOBests$procOb)
        list("bootObj632ests" = bootObj632ests, "margVar" = var(trainDat$y))
         })
        out = list("resList" = resList, 'trueMSE' = trueMSE, "trueMargVar" = margVar)
        save(out, file = sweepFile)
        } else load(sweepFile)
        out
  })
  save(file = bootHDSweepFile, sweepHDboot)
} else load(bootHDSweepFile) 
```

```{r processSweepHDBoot}
if(!file.exists(sweepProcessFileHDboot <- 'simResults/sweepProcessFileHDboot.RData')){
    sweepProcessHDboot = lapply(seq_len(nrow(gridSweepHighBoot)), function(i){
        obj = sweepHDboot[[i]]
        n = gridSweepHighBoot[i, "samSize"]
        oracleRho = cor(t(sapply(obj$resList, function(x) c(x$bootObj632ests[["procOb"]][ "MSEhat",], x[["margVar"]]))))[1,2]
        rhoSEmat = lapply(obj$resList, function(xxx, oracleRho, oracleSE){
            with(xxx, {
                margVarOut = margVar*(n+1)/n
                rhosMat = cbind("bootRhos" = cor(bootObj632ests$procBoot, bootObj632ests$margVarBoot),
                "bootRhosParam" = cor(bootObj632ests$procBootParam, bootObj632ests$margVarBootParam),
                 "jnRhos" = cor(bootObj632ests$procJack, bootObj632ests$margVarJack),
                "oracleRho" = oracleRho)
                MSEs = bootObj632ests$procOb["MSEhat",]
                bootEstsR2 = 1-(bootObj632ests$procBoot/bootObj632ests$margVarBoot)*n/(n+1)
                bootEstsR2param = 1 - bootObj632ests$procBootParam/bootObj632ests$margVarBootParam*n/(n+1)
                sesMat = c(apply(rhosMat, 2, function(rho){
                        RsquaredSE(MSE = bootObj632ests$procOb["MSEhat", ], n = gridSweepHighBoot[i, 'samSize'], margVar =                               margVarOut, SEMSE = bootObj632ests$procOb["SEhat", ], rhoBoot = rho)[2]
                }),
                "bootSEs" = sd(bootEstsR2),
                "bootParamSEs" = sd(bootEstsR2param),
                "oracleSE"  = oracleSE
                )
                bootQuantiles = quantile(bootEstsR2, quantsSweep)
                bootQuantilesParam = quantile(bootEstsR2param, quantsSweep)
                BCa = buildBCa(Rsq <- 1-MSEs/margVarOut, bootEstsR2, jackR2 <- 1-(bootObj632ests$procJack/ bootObj632ests$margVarJack)*n/(n+1), sigLevel)
                BCaparam = buildBCa(Rsq, bootEstsR2param, jackR2, sigLevel)
                list("MSEhat" = MSEs, "margVar" = margVarOut, "ses" = sesMat, "rhosMat" = rhosMat,
                     bootQuants = rbind("boot" = bootQuantiles, "bootparam" = bootQuantilesParam, 
                                        "BCa" = BCa, "BCaParam" = BCaparam
                                        ))
            })
        }, oracleRho = oracleRho, oracleSE = oracleSE <- sd(sapply(obj$resList, function(x) x[["bootObj632ests"]]$procOb["MSEhat", ]/x[["margVar"]])))
        lapply(rhoSEmat, function(x) {
            x$ses = c(x$ses, "oracleSE" = oracleSE)
            x$true = c("trueMSE" = mean(obj[["trueMSE"]]), "trueMargVar" = obj[["trueMargVar"]]*(n+1)/n)
        x})
        })
    save(sweepProcessHDboot, file = sweepProcessFileHDboot)
} else load(sweepProcessFileHDboot)
```

```{r trueR2HD, results = 'asis'}
trueR2sAllhdtrue = Reduce(f = rbind, lapply(idHighExist, function(i){
    cbind(gridSweepHigh[i,], 'R2' = 1-sweepProcessHD[[i]][[1]]$true["trueMSE"]/sweepProcessHD[[i]][[1]]$true["trueMargVar"])
})) 
R2mataggHd = aggregate(R2 ~ betas + samSize, data = trueR2sAllhdtrue, FUN = mean)
R2cast = acast(R2mataggHd, betas~ samSize, value.var = "R2")
names(dimnames(R2cast)) <- c("Effect size", "Sample size")
print.xtableFtable(xtableFtable(ftable(round(R2cast,3), method = "non.compact"), digits = 3, caption = "Monte-Carlo approximated true $R^2$ values for high-dimensional scenario for different sample sizes (columns) and effect sizes $\\beta$ (rows).\\label{tab:trueR2HD}"), comment = FALSE)
```

```{r trueSER2HD, results = 'asis', include = FALSE}
trueR2sAllhdSE = cbind(gridSweepHigh[idHighExist,], 'SER2' = sapply(idHighExist, function(i){
    sweepProcessHD[[i]][[1]]$ses[['oracleSE']]
    })
)
trueR2sAllhd = Reduce(f = rbind, lapply(idHighExist, function(i){
    cbind(gridSweepHigh[i,], 'R2' = sapply(sweepProcessHD[[i]], function(x){
        n = gridSweepHigh[i,"samSize"]
        1-x[['MSEhat']]/x[['margVar']]*n/(n+1)
    }))
}))
R2matagg = trueR2sAllhd
R2cast = acast(R2matagg[with(R2matagg, bootReps==100 & cvSplits == 100),], betas~ samSize, value.var = "R2", fun.aggregate = sd)
names(dimnames(R2cast)) <- c("Effect size", "Sample size")
print.xtableFtable(xtableFtable(ftable(round(R2cast,3), method = "non.compact"), digits = 3, caption = "Monte-Carlo approximated true standard errors (SE) of the $R^2$ estimated through cross-validation with 100 splits and 100 bootstrap instances for the high-dimensional scenario for different sample sizes (columns) and effect sizes $\\beta$ (rows).\\label{tab:trueSER2HD}"), comment = FALSE)
```

```{r trueSEfigCvHD, fig.cap = "Monte-Carlo approximated true standard errors (SE) of the \\hrsq (y-axis) estimated through cross-validation in the high-dimensional scenario for different sample sizes (x-axis), effect sizes $\\beta$ (top panels) and number of cross-validation splits (line type). The SE increases with the sample size because also the true \\rsq increases with sample size (Table \\ref{tab:trueR2HD}).\\label{fig:trueSER2HD}", fig.height=3.5}
linetypesHigh = c("solid", "dashed", "dotdash"); names(linetypesHigh) = cvSplitsSweepHigh
R2mataggFigCV = aggregate(R2 ~ betas + cvSplits + samSize, data = trueR2sAllhd[with(trueR2sAllhd,bootReps == 10),], FUN = sd)
ggplot(data = R2mataggFigCV, mapping = aes_string(x = "samSize", y = "R2", linetype = "factor(cvSplits)")) + geom_line() + scale_linetype_manual(values = linetypesHigh) + guides(linetype = guide_legend("Number of cross-validation splits")) + 
    facet_grid(~betas) + xlab("Sample size") + ylab(bquote("Standard error of the "*R^2*" estimator"))
```

```{r trueSER2HDboot, results = 'asis', include = FALSE}
trueR2sAllhdBoot = Reduce(f = rbind, lapply(seq_along(sweepProcessHDboot), function(i){ 
    cbind(gridSweepHighBoot[i,], 'R2' = sapply(sweepProcessHDboot[[i]], function(x){
        n = gridSweepHighBoot[i,"samSize"]
        1-x[['MSEhat']]/x[['margVar']]*n/(n+1)
    }))
}))
trueR2sAllhdSE = Reduce(f = rbind, lapply(seq_along(sweepProcessHD)[idHighExist], function(i){
    cbind(gridSweepHigh[i,], 'SER2' = sapply(sweepProcessHD[[i]], function(x){
        x$ses[['oracleSE']]
    }))
}))
R2matagg = aggregate(R2 ~ betas + samSize, data = trueR2sAllhdBoot[with(trueR2sAllhdBoot, bootReps == 200 & bootRepsOuter == 30),], FUN = sd)
R2cast = acast(R2matagg, betas~ samSize, value.var = "R2")
names(dimnames(R2cast)) <- c("Effect size", "Sample size")
print.xtableFtable(xtableFtable(ftable(round(R2cast,3), method = "non-compact"), digits = 3, caption = "Monte-Carlo approximated true standard errors (SE) of the $R^2$ estimated through the .632 bootstrap with 200 outer and 30 inner bootstrap instances for the high-dimensional scenario for different sample sizes (columns) and effect sizes $\\beta$ (rows).\\label{tab:trueSER2HDboot}"), comment = FALSE)
```

```{r trueSEfigBootHD, fig.cap = "Monte-Carlo approximated true standard errors (SE) of the \\hrsq (y-axis) in the high-dimensional scenario estimated through the .632 bootstrap for the high-dimensional scenario for different sample sizes (x-axis), effect sizes $\\beta$ (top panels) and number of .632 bootstraps (line type). \\label{fig:trueSER2HDboot}", fig.height=3.5}
R2mataggFig = aggregate(R2 ~ betas + samSize + bootReps, data = trueR2sAllhdBoot[with(trueR2sAllhdBoot,bootRepsOuter == 30),], FUN = sd)
ggplot(data = R2mataggFig, mapping = aes_string(x = "samSize", y = "R2", linetype = "factor(bootReps)")) + geom_line() + guides(linetype = guide_legend("Number of .632 bootstraps")) + 
    facet_grid(~betas) + xlab("Sample size") + ylab(bquote("Standard error of the "*R^2*" estimator"))
```

\clearpage

### Alternative estimators for the \rsq \label{sec:altEst}

```{r r2estHigh, fig.cap = "Boxplots of \\rsq values estimated in three different ways for the high-dimensional scenario using cross-validation (x-axis, see Section \\ref{sec:estR2} in the main text) for different sample sizes (side panels) and effect sizes (top panels). Simple, non-nested CV is used to estimate the MSE. Diamonds indicate means; the plot was trunctated at -1 for legibility. The dashed horizontal line indicates the true \\rsq approximated through Monte-Carlo simulation from Table \\ref{tab:trueR2HD}.\\label{fig:altR2high}", fig.height = 7}
gridAvHigh = expand.grid('samSize' = samSize[-1], 'betas' = betas[-4])
nSimAvHigh = 1e2
if(!file.exists(avR2highFile <- "Results/avR2high.RData")){
    avR2highs = mclapply(mc.cores = nCores, seq_len(nrow(gridAvHigh)), function(j){
        vapply(integer(nSimAvHigh), FUN.VALUE = double(3), function(i){
            nAv = gridAvHigh[j, "samSize"]
            foldsAv = sample(rep(unFolds, length.out = nAv))
            trainDat = genDat(nAv, p, betas = betasHigh[as.character(gridAvHigh[j, "betas"]),])
            R2s = vapply(unFolds, FUN.VALUE = double(3), function(uf){
                    idTrain = foldsAv!=uf
                    predTest = predGlmnet(trainDat$x[idTrain,], trainDat$y[idTrain], trainDat$x[!idTrain,], alpha = alpha)
                    MSE = mean((predTest-trainDat$y[!idTrain])^2)
                    MST = var(trainDat$y[idTrain])*(sum(idTrain)+1)/sum(idTrain)
                    MSTtest = var(trainDat$y[!idTrain])
                    c("MSE" = MSE, "R2" = 1-MSE/MST, "R2test" = 1-MSE/MSTtest)
                })
            MSTtot = var(trainDat$y)*(nAv+1)/nAv
            c("Pooling R2" = 1-mean(R2s["MSE",])/MSTtot, "Averaging R2\ntraining MST" = mean(R2s[ "R2",]), "Averaging R2\ntest MST" = mean(R2s[ "R2test",]))
        })
    })
    save(avR2highs, file = avR2highFile)
} else load(avR2highFile)
R2mataggHigh = aggregate(R2 ~ betas + samSize, data = trueR2sAllhdtrue, FUN = mean)
moltAvR2high = melt(id.vars = c("samSize", "betas"), Reduce(f = rbind, lapply(seq_along(avR2highs), function(x) cbind(t(avR2highs[[x]]), gridAvHigh[x, ]))))
moltAvR2agg = aggregate(value ~ samSize + betas + variable, FUN = mean, data = moltAvR2high)
moltAvR2high$samSize = factor(moltAvR2high$samSize);moltAvR2high$betas = factor(moltAvR2high$betas)
R2mataggHigh$samSize = factor(R2mataggHigh$samSize);R2mataggHigh$betas = factor(R2mataggHigh$betas)
ggplot(data = moltAvR2high, aes(y = value, col = variable, x = variable)) + geom_boxplot() +
    stat_boxplot(geom ='errorbar', width = 0.5) + 
    facet_grid(samSize ~ betas, scale = "free_y") + coord_cartesian(ylim = c(-1, max(moltAvR2high$value))) +
    geom_point(data = moltAvR2agg, aes(x = variable, y = value), shape = 5) +
    geom_hline(data = R2mataggHigh[R2mataggHigh$samSize %in% unique(gridAvHigh$samSize),], 
               aes(yintercept = R2), linetype = "dotted") +
    scale_colour_discrete(name = "Estimation method") +
    theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) +
    ylab("R² estimate") + xlab("")
```

\clearpage

### Bias \label{sec:biasHD}

```{r CVEstimationHDboot, fig.height = 4, fig.cap = "Bias of the MSE estimation over 100 Monte-Carlo instances (y-axis) through cross-validation and .632 bootstrap (top panels) for the high-dimensional scenario as a function of sample size (x-axis) and signal strength (side panels) for 100 cross-validation splits and 200 bootstraps. The horizontal dotted line at 0 indicates no bias. For strong signals, the estimation of the MSE becomes difficult, since the true MSE may in some range decrease quickly with sample size for high-dimensional models, and resampling algorithms fail to detect this.\\label{fig:biasMSEHD}", fig.width = 4.2}
biasCVHD = cbind("biasMSE" = sapply(sweepProcessHD, function(x){
    mean(sapply(x, function(y){
        y$MSEhat-y$true["trueMSE"]
    }))
}), gridSweepHigh)
biasHDAggCV = aggregate(biasMSE~ samSize + betas, biasCVHD[biasCVHD$cvSplits == 100,], FUN = mean)
biasHDAggCV$Resampling_algorithm = "Cross-validation"
biasBootHD = cbind("biasMSE" = sapply(sweepProcessHDboot, function(x){
    mean(sapply(x, function(y){
        y$MSEhat-y$true["trueMSE"]
    }))
}), gridSweepHighBoot)
biasHDAggBoot = aggregate(biasMSE~ samSize + betas, biasBootHD[biasBootHD$bootReps == 200,], FUN = mean)
biasHDAggBoot$Resampling_algorithm = "Bootstrap"
biasHDAgg = rbind(biasHDAggCV, biasHDAggBoot)
ggplot(data = biasHDAgg, aes_string(y = "biasMSE", x = "samSize")) + geom_line() + facet_grid(betas ~ Resampling_algorithm)+
    xlab("Sample size") + scale_x_continuous(breaks = samSizeHigh) + theme(axis.text.x = element_text(angle=60)) + ylab(bquote('Bias of MSE estimation')) + geom_hline(yintercept = 0, linetype = "dotted")
```

```{r R2EstimationHD, fig.height = 4, fig.cap = "Bias of the \\rsq estimation (y-axis) through cross-validation and bootstrap (top panels) over 100 Monte-Carlo instances for the high-dimensional scenario as a function of sample size (x-axis) and signal strength (side panels) for 100 cross-validation splits and 200 bootstraps. The horizontal dotted line at 0 indicates no bias. At high sample sizes and effect sizes, the out-of-sample \\rsq is underestimated, implying a conservative assessment of predictive performance. This bias may contribute to the poor coverage of the confidence intervals for high sample sizes (\\fref{fig:HighDim}).\\label{fig:biasR2HD}", fig.width = 4.2}
biasCVHD = cbind("biasR2" = sapply(sweepProcessHD, function(x){
    mean(sapply(x, function(y){
        estR2 = 1-y$MSEhat/y$margVar
        trueR2 = 1-y$true["trueMSE"]/y$true["trueMargVar"]
        estR2 - trueR2
    }))
}), gridSweepHigh)
biasHDAggCV = aggregate(biasR2~ samSize + betas, biasCVHD[biasCVHD$cvSplits == 100,], FUN = mean)
biasHDAggCV$Resampling_algorithm = "Cross-validation"
biasBootHD = cbind("biasR2" = sapply(sweepProcessHDboot, function(x){
    mean(sapply(x, function(y){
        estR2 = 1-y$MSEhat/y$margVar
        trueR2 = 1-y$true["trueMSE"]/y$true["trueMargVar"]
        estR2 - trueR2
    }))
}), gridSweepHighBoot)
biasHDAggBoot = aggregate(biasR2~ samSize + betas, biasBootHD[biasBootHD$bootReps == 200,], FUN = mean)
biasHDAggBoot$Resampling_algorithm = "Bootstrap"
biasHDAgg = rbind(biasHDAggCV, biasHDAggBoot)
ggplot(data = biasHDAgg, aes_string(y = "biasR2", x = "samSize")) + geom_line() + facet_grid(betas ~ Resampling_algorithm)+
    xlab("Sample size") + scale_x_continuous(breaks = samSizeHigh) + theme(axis.text.x = element_text(angle=60)) + ylab(bquote('Bias of '*R^2*' estimation')) + geom_hline(yintercept = 0, linetype = "dotted")
```

\clearpage

### Variance

#### Cross-validation

In the high-dimensional scenario with zero effect size, estimating the correlation between $\widehat{MSE}$ and $\widehat{MST}$ is a serious challenge (\fref{fig:corEstHD}), contributing to overestimation of the SE (\fref{fig:HighDim}). 

```{r checkSEhigh, fig.height = 6, fig.cap="Geometric mean of log10 ratio of the estimated to the Monte-Carlo approximated true SE of the cross-validation \\rsq over 100 Monte-Carlo instances for the high-dimensional scenario (y-axis) as a function of sample size (x-axis), number of bootstrap replicates (top panels) and signal strength (side panels). The dotted line at 0 is a visual aid.\\label{fig:biasHigh}"}
biasProcSE = cbind(gridSweepHigh[idHighExist,], t(sapply(seq_len(nrow(gridSweepHigh))[idHighExist], function(i){ 
    sMat = t(sapply(sweepProcessHD[[i]], function(x){
        x$ses
    }))
    (colMeans(log10(sMat[, colnames(sMat)!= "oracleSE"]/sMat[, "oracleSE"])))
})))
biasProcSENMolt = melt(biasProcSE, id.vars = names(gridSweepHigh), variable.name ="Method", value.name = "BiasSE")
biasProcSENMolt$Method = factor(biasProcSENMolt$Method, levels = methodLevels, 
                             labels = methodLabels)
labels2plotHigh = c("Delta method SE (nonparametric bootstrap)", "Delta method SE (parametric bootstrap)",
  "Delta method SE (jackknife)",  "Bootstrap SE (nonparametric)", "Bootstrap SE (parametric)" , "Percentile bootstrap", "Percentile parametric bootstrap", "BCa", "BCa (parametric)")
ggplot(data = biasProcSENMolt[biasProcSENMolt$Method %in% labels2plotHigh,], aes_string(y = "BiasSE", x = "samSize", colour = "Method", linetype = "factor(cvSplits)")) + geom_line() + facet_grid(betas ~ bootReps, scale = "free_y")+ guides(linetype = guide_legend("Number of cross-validation splits"))+
    xlab("Sample size") + ylab(bquote("Log10 ratio of the estimated SE of the "*R^2*" to the approximated true SE")) + geom_hline(yintercept = 0, size = 0.5, linetype = "dotted") + scale_linetype_manual(values = linetypesHigh)+
    scale_colour_manual(values = methodColours[names(methodColours) %in% labels2plotHigh[1:5]]) + scale_x_continuous(breaks = samSizeHigh) + theme(axis.text.x = element_text(angle = 60))
```

```{r checkSEhighMSE, fig.cap="MSE of the estimated SE of the cross-validation \\rsq for the high-dimensional scenario (y-axis) as a function of sample size (x-axis), number of bootstrap replicates (top panels) and signal strength (side panels). The y-axis is on the log scale.\\label{fig:mseHigh}"}
biasProcSEmse = cbind(gridSweepHigh[idHighExist,], t(sapply(seq_len(nrow(gridSweepHigh))[idHighExist], function(i){ 
    sMat = t(sapply(sweepProcessHD[[i]], function(x){
        x$ses
    }))
    (colMeans((sMat[, colnames(sMat)!= "oracleSE"]-sMat[, "oracleSE"])^2))
})))
biasProcSENMoltmse = melt(biasProcSEmse, id.vars = names(gridSweepHigh), variable.name ="Method", value.name = "BiasSE")
biasProcSENMoltmse$Method = factor(biasProcSENMoltmse$Method, levels = methodLevels, 
                             labels = methodLabels)
ggplot(data = biasProcSENMoltmse[biasProcSENMoltmse$Method %in% labels2plotHigh,], aes_string(y = "BiasSE", x = "samSize", colour = "Method", linetype = "factor(cvSplits)")) + geom_line() + facet_grid(betas ~ bootReps, scale = "free_y") + guides(linetype = guide_legend("Number of cross-validation splits")) +
    xlab("Sample size") + ylab(bquote("MSE of estimated SE of the "*R^2)) + scale_linetype_manual(values = linetypesHigh) + scale_y_log10() +
    scale_colour_manual(values = methodColours[names(methodColours) %in% labels2plotHigh[1:5]]) + scale_x_continuous(breaks = samSizeHigh) + theme(axis.text.x = element_text(angle=60))
```

```{r deeperLookHD, fig.cap = "Boxplots of estimated correlation between MSE and MST estimators using different methods (colour) for different signal strengths (side panels) and sample sizes (top panels) for the high-dimensional scenario with cross-validation over 100 Monte-Carlo instances. The Monte-Carlo approximated true correlation is shown as a dashed line, the dotted line at 0 is a visual aid. In this scenario, no method succeeds in accurately estimating the correlation in all scenarios, but jackknifing performs relatively best. Because the fitted EN model is often sparse, parametric bootstrapping often generates outcomes unrelated to the regressors, leading to high correlation between the MSE and MST estimators.\\label{fig:corEstHD}"}
oracleCors = sapply(seq_len(nrow(gridSweepHigh))[idHighExist], function(i){
        obj = sweepHD[[i]]
        cor(t(sapply(obj$resList, function(x) c(x[["singleModsBates"]]["Bates", "MSEhat"], x[["margVar"]]))))[1,2]
}) 
#Correlation MSE and MST estimators becomes negative at high sample size-high signal
rhoList = lapply(seq_len(nrow(gridSweepHigh))[idHighExist], function(i){
        obj = sweepProcessHD[[i]]
        mat = t(sapply(obj, function(x) c(x$rhosMat)))
        colnames(mat) = colnames(obj[[1]]$rhosMat)
        mat[, c("bootRhos", "bootRhosParam", "jnRhos")]
}); names(rhoList) = seq_len(nrow(gridSweepHigh))[idHighExist]
oracleDf = data.frame("oracleCor" = oracleCors, gridSweepHigh[idHighExist,])
moltRhoList = melt(rhoList)
colnames(moltRhoList) = c("Rep", "Method", "Correlation", "L1")
moltRhoList$Method = factor(moltRhoList$Method, levels = methodLevels, labels = labNew)
moltRhoList = cbind(moltRhoList, gridSweepHigh[as.integer(moltRhoList$L1),])
ggplot(data = moltRhoList[with(moltRhoList, bootReps==bootRepsSweepHigh[2] & cvSplits==cvSplitsSweepHigh[2]),], aes_string(y = "Correlation", color = "Method")) + geom_boxplot() + ylab("Estimated correlation between MSE and MST estimators") +
    facet_grid(betas ~ samSize) + geom_hline(data = oracleDf[with(oracleDf, bootReps==bootRepsSweepHigh[2] & cvSplits==cvSplitsSweepHigh[2]),], aes(yintercept = oracleCor), linetype = "dashed") + geom_hline(yintercept = 0, linetype = "dotted") + 
    theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) +
    scale_colour_manual(values = coloursCor[levels(moltRhoList$Method) %in% names(coloursCor)[1:4]])
```

```{r risweepCovProcHD}
ses = c("bootRho", "bootParamRho", "cvRho", "oracleRho", "seBoot", "seBootParam", "seOracle"); names(ses) = ses
r2cisweepCIhigh = lapply(seq_len(nrow(gridSweepHigh)), function(i){
    if(!(i %in% idHighExist)){return(NULL)}
    lapply(sweepProcessHD[[i]], function(x){
        R2 = 1-x[['MSEhat']]/x[['margVar']]
        CI = R2 + outer(x[['ses']], Quants)
        rownames(x[["bootQuants"]])[1:2] = paste0(rownames(x[["bootQuants"]])[1:2], "Percentile")
        CI = rbind(CI, x[["bootQuants"]])
        CI[, 2] = sapply(CI[, 2], min, 1)
        CI
    })
})
r2cisweepNonCov = lapply(seq_len(nrow(gridSweepHigh))[idHighExist], function(i){
    trueR2 = 1 - sweepProcessHD[[i]][[1]]$true[["trueMSE"]]/sweepProcessHD[[i]][[1]]$true[["trueMargVar"]]
    vapply(r2cisweepCIhigh[[i]], FUN.VALUE = matrix(TRUE, nrow(r2cisweepCIhigh[[i]][[1]]),2), function(CI){
        cbind("under" = trueR2 < CI[,1], "over" = trueR2 > CI[,2])
    })
})
r2cisweepCovSum = t(sapply(r2cisweepNonCov, function(x) rowMeans(!apply(x, c(1,3), any, na.rm = TRUE))))
r2cisweepWidth = lapply(seq_len(nrow(gridSweepHigh))[idHighExist], function(i){
    sapply(r2cisweepCIhigh[[i]], function(CI){
        apply(CI, 1, diff)
    })
})
r2cisweepWidthSumHD = t(sapply(r2cisweepWidth, rowMeans, na.rm = TRUE))
sweepSum = cbind(gridSweepHigh[idHighExist,], r2cisweepCovSum)
sweepSumMoltHigh = melt(sweepSum, id.vars = names(gridSweepHigh), 
                        value.name = "Coverage", variable.name = 'Method')
sweepSumMoltHigh$betas = factor(sweepSumMoltHigh$betas)
sweepSumMoltHigh$Method = factor(sweepSumMoltHigh$Method, levels = methodLevels, labels = methodLabels) 
labels2plotHigh = c("Delta method SE (nonparametric bootstrap)", "Delta method SE (parametric bootstrap)",
  "Delta method SE (jackknife)",  "Bootstrap SE (nonparametric)", "Bootstrap SE (parametric)" , "Percentile bootstrap", "Percentile parametric bootstrap", "BCa", "BCa (parametric)")
```

```{r risweepCovHD, fig.cap = 'Coverage of the 95\\% confidence intervals for the cross-validation \\rsq (y-axis) for different sample sizes (x-axis), methods (colour), signal strength (side panel) and number of bootstrap replicates (top panels) for 100 repeats of the cross-validation splits for the high-dimensional scenario.\\label{fig:sweepCovHD}'}
ggplot(data = sweepSumMoltHigh[with(sweepSumMoltHigh, cvSplits==100 & Method %in% labels2plotHigh),], aes(x = samSize, y = Coverage, col = Method, )) + geom_line() + facet_grid(betas~ bootReps, scale = "free_y") +
    geom_hline(yintercept = 1-sigLevel, linetype = 'dotted')+ ylab(bquote("Coverage of the 95% confidence intervals for the "*R^2)) + scale_colour_manual(values = methodColours[names(methodColours) %in% labels2plotHigh]) + xlab("Sample size") + scale_x_continuous(breaks = samSizeHigh) + theme(axis.text.x = element_text(angle=60))
```

```{r plotwidthsweepHD, fig.cap = 'Average width of the 95\\% confidence intervals for the cross-validation \\rsq (y-axis) for different sample sizes (x-axis), method (colour), signal strength (side panel) and number of bootstrap replicates (top panels) for 100 repeats of the cross-validation splits for the high-dimensional scenario.\\label{fig:sweepWidthHD}'}
sweepSumW = cbind(gridSweepHigh[idHighExist,], r2cisweepWidthSumHD)
sweepSumMoltW = melt(sweepSumW, id.vars = names(gridSweepHigh), value.name = "Width_of_confidence_interval", variable.name = 'Method')
sweepSumMoltW$betas = factor(sweepSumMoltW$betas)
sweepSumMoltW$Method = factor(sweepSumMoltW$Method, levels = methodLevels, labels = methodLabels)
ggplot(data = sweepSumMoltW[with(sweepSumMoltW,cvSplits==100 & Method %in% labels2plotHigh),], aes(x = samSize, y = Width_of_confidence_interval, col = Method)) + geom_line() + facet_grid(betas~ bootReps, scale = "free_y")+ ylab(bquote("Width of the confidence interval for "*R^2)) + xlab("Sample size") +
    ylab(bquote("Average width of the 95% confidence intervals for the "*R^2)) +
    scale_colour_manual(values = methodColours[names(methodColours) %in% labels2plotHigh])+xlab("Sample size") + scale_x_continuous(breaks = samSizeHigh) + theme(axis.text.x = element_text(angle=60))
```

```{r zTestHD, fig.height = 6, fig.cap = "Type I error of approximate one-sided z-tests that \\rsq $\\leq$ 0  (y-axis) as a function of sample size (y-axis), effect size (top panels) and number of cross-validation splits (side panels) for cross-validation in the high-dimensional scenario with number of bootstrap replicates 100. The horizontal dotted line indicates the significance level of 5\\%. Results are shown for all approximate true \\rsq values below 0 (see Table \\ref{tab:trueR2HD}). The parametric boostrap SE method does not control the type I error at the significance level of 5\\% in all cases.\\label{fig:zTestHD}"}
#Evaluate one-sided approximate z-test
idNullHDagg = R2mataggHd[, "R2"]<0
idNullHD <- sapply(seq_len(nrow(gridSweepHigh)), function(i){
            any(R2mataggHd[idNullHDagg, "betas"] %in% gridSweepHigh[i, "betas"] & 
                    R2mataggHd[idNullHDagg, "samSize"] %in% gridSweepHigh[i, "samSize"])
})
zTestEvalHD = lapply(which(idNullHD), function(i){
    sapply(sweepProcessHD[[i]], function(y){
        with(y, {
            R2hat = 1-MSEhat/margVar
            pnorm(R2hat/ses, lower.tail = FALSE)
        })
    })
})
#Calculate type I error
typeIerrorZ = cbind(gridSweepHigh[idNullHD, ], t(sapply(zTestEvalHD, function(x){
    rowMeans(x < sigLevel)
})))
typeIerrorZMolt = melt(typeIerrorZ, id.vars = colnames(gridSweepHigh), variable.name = "Method", value.name = "Type_I_error")
typeIerrorZMolt$Method = factor(typeIerrorZMolt$Method, levels = methodLevels, labels = methodLabels)
ggplot(data = typeIerrorZMolt[with(typeIerrorZMolt, Method %in% labels2plotHigh & bootReps==100),], aes_string(x = "samSize", y = "Type_I_error", col = "Method")) + geom_point(size = typeIerrorPointSize, position = position_dodge(width = dodgeTypeI)) + facet_grid(cvSplits ~ betas) + xlab("Sample size") + geom_hline(linetype = "dotted", yintercept = sigLevel)+ 
    scale_colour_manual(values = methodColours[names(methodColours) %in% intersect(typeIerrorZMolt$Method, labels2plot)]) + scale_x_continuous(breaks = samSizeHigh) + theme(axis.text.x = element_text(angle=60)) +ylab("Type I error")
```

```{r oneDimCombiPlotHigh, include = FALSE}
moltBiasHigh = melt(biasProcSENMolt, id.vars = c("samSize", "betas", "bootReps", "cvSplits", "Method"))
moltCovHigh = melt(sweepSumMoltHigh, id.vars = c("samSize", "betas", "bootReps", "cvSplits", "Method"))
moltAllHigh = rbind(moltCovHigh, moltBiasHigh) 
biasName = "Log10(estimated/true standard error)"
moltAllHigh$variable = factor(as.character(moltAllHigh$variable), levels = c("BiasSE", "Coverage"), labels = c(biasName, "Coverage"), ordered = TRUE)
moltAllHigh = droplevels(moltAllHigh)
dfLine = data.frame("variable" = c(biasName, "Coverage"), "yintercept" = c(0, 1-sigLevel))
dfLine$variable = factor(as.character(dfLine$variable), levels = c(biasName, "Coverage"), labels = c(biasName, "Coverage"), ordered = TRUE)
HighDimplot = ggplot(data = moltAllHigh[with(moltAllHigh, cvSplits == 100 & bootReps == 100 & Method %in% labels2plot), ], aes_string(y = "value", x = "samSize", colour = "Method")) + geom_line() + facet_grid(variable~betas, scale = "free_y") + guides(linetype = guide_legend("Number of cross-validation splits")) + 
    xlab("Sample size") + ylab("Diagnostic") + 
    geom_hline(data = dfLine, aes(yintercept = yintercept), linetype = "dotted") + scale_colour_manual(values = methodColours[names(methodColours) %in% labels2plot]) + 
    scale_x_continuous(breaks = samSize) + theme(axis.text.x = element_text(angle=60))
ggsave(HighDimplot, file = "Graphs/highDimCombi.pdf", height = 5.3, width = 7.5)
```

\clearpage

#### The .632 bootstrap

```{r checkSEhighBoot, fig.cap= "Log10 ratio of the estimated to the Monte-Carlo approximated true SE of the .632 bootstrap \\rsq  (y-axis) across 100 Monte-Carlo instances for the high-dimensional scenario as a function of sample size (x-axis), number of bootstrap replicates (top panels) and signal strength (side panels). The dotted line at 0 is a visual aid. The delta method SE with nonparametric bootstrap or jackknife is the only method that never underestimates the SE.\\label{fig:biasHighBoot}"}
biasProcSEboot = cbind(gridSweepHighBoot, t(sapply(seq_len(nrow(gridSweepHighBoot)), function(i){ 
    sMat = t(sapply(sweepProcessHDboot[[i]], function(x){
        x$ses
    }))
    (colMeans(na.rm = TRUE, log10(sMat[, colnames(sMat)!= "oracleSE"]/sMat[, "oracleSE"])))
})))
biasProcSENMolt = melt(biasProcSEboot, id.vars = names(gridSweepHighBoot), variable.name ="Method", value.name = "BiasSE")
biasProcSENMolt$Method = factor(biasProcSENMolt$Method, levels = methodLevels, labels = methodLabels)
ggplot(data = biasProcSENMolt[biasProcSENMolt$Method %in% labels2plotHigh,], aes_string(y = "BiasSE", x = "samSize", colour = "Method", linetype = "factor(bootRepsOuter)")) + geom_line() + facet_grid(betas ~ bootReps, scale = "free_y")+ guides(linetype = guide_legend("Number of outer bootstraps"))+
    xlab("Sample size") + ylab(bquote("Log10 ratio of the estimated SE of the "*R^2*" to the approximated true SE")) + geom_hline(yintercept = 0, size = 0.5, linetype = "dotted") +
    scale_colour_manual(values = methodColours[names(methodColours) %in% labels2plotHigh[1:5]]) + scale_x_continuous(breaks = samSizeHigh) + theme(axis.text.x = element_text(angle=60))
```

```{r checkSEhighMSEboot, fig.cap="MSE of the estimated SE of the .632 bootstrap \\rsq for the high-dimensional scenario (y-axis) as a function of sample size (x-axis), number of bootstrap replicates (top panels) and signal strength (side panels). The y-axis is on the log scale.\\label{fig:mseHighBoot}"}
biasProcSE = cbind(gridSweepHighBoot, t(sapply(seq_len(nrow(gridSweepHighBoot)), function(i){ 
    sMat = t(sapply(sweepProcessHDboot[[i]], function(x){
        x$ses
    }))
    (colMeans(na.rm = TRUE, (sMat[, colnames(sMat)!= "oracleSE"]-sMat[, "oracleSE"])^2))
})))
biasProcSENMolt = melt(biasProcSE, id.vars = names(gridSweepHighBoot), variable.name ="Method", value.name = "BiasSE")
biasProcSENMolt$Method = factor(biasProcSENMolt$Method, levels = methodLevels, 
                             labels = methodLabels)
ggplot(data = biasProcSENMolt[biasProcSENMolt$Method %in% labels2plotHigh,], aes_string(y = "BiasSE", x = "samSize", colour = "Method", linetype = "factor(bootRepsOuter)")) + geom_line() + facet_grid(betas ~ bootReps, scale = "free_y")+ guides(linetype = guide_legend("Number of outer bootstraps"))+
    xlab("Sample size") + ylab(bquote("MSE of estimated SE of the "*R^2)) + scale_y_log10() +
    scale_colour_manual(values = methodColours[names(methodColours) %in% labels2plotHigh[1:5]]) + scale_x_continuous(breaks = samSizeHigh) + theme(axis.text.x = element_text(angle=60))
```

```{r deeperLookHDboot, fig.cap = "Boxplots of estimated correlation between MSE and MST estimators across 100 Monte-Carlo instances using different methods (colour) for different signal strengths (side panels) and sample sizes (top panels) for the high-dimensional scenario with .632 bootstrap estimation. The Monte-Carlo approximated true correlation is shown as a dashed line, the dotted line at 0 is a visual aid. Neither method consistently estimates the correlation $\\rho$ well.\\label{fig:corEstHDBoot}"}
oracleCorsBoot = sapply(seq_len(nrow(gridSweepHighBoot)), function(i){
        obj = sweepHDboot[[i]]
        cor(t(sapply(obj$resList, function(x) c(x$bootObj632ests$procOb["MSEhat",], x[["margVar"]]))))[1,2]
}) 
#Correlation MSE and MST estimators becomes negative at high sample size-high signal
#Really fascinating: at high signal, high sample size, the correlation shrinks and even becomes negative. Only nonparametric bootstrapping captures this? Larger MST = more variable predictors = Higher information content??
rhoList = lapply(seq_len(nrow(gridSweepHighBoot)), function(i){
        obj = sweepProcessHDboot[[i]]
        mat = t(sapply(obj, function(x) c(x$rhosMat)))
        colnames(mat) = colnames(obj[[1]]$rhosMat)
        mat[, c("bootRhos", "bootRhosParam", "jnRhos")]
}); names(rhoList) = seq_len(nrow(gridSweepHighBoot))
oracleDf = data.frame("oracleCor" = oracleCorsBoot, gridSweepHighBoot)
moltRhoList = melt(rhoList)
colnames(moltRhoList) = c("Rep", "Method", "Correlation", "L1")
moltRhoList$Method = factor(moltRhoList$Method, levels = methodLevels, labels = methodLabels)
moltRhoList = cbind(moltRhoList, gridSweepHighBoot[as.integer(moltRhoList$L1),])
ggplot(data = moltRhoList[with(moltRhoList, bootReps==bootRepsSweepBoot[2] & bootRepsOuter==bootRepsSweepHighOuter[2]),], aes_string(y = "Correlation", color = "Method")) + geom_boxplot() + ylab("Estimated correlation between MST and MSE estimators") +
    facet_grid(betas ~ samSize) + geom_hline(data = oracleDf[with(oracleDf, bootReps==bootRepsSweepBoot[2] & bootRepsOuter==bootRepsSweepHighOuter[2]),], aes(yintercept = oracleCor), linetype = "dashed") + geom_hline(yintercept = 0, linetype = "dotted") + 
    theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) +
    scale_colour_manual(values = methodColours[names(methodColours) %in% labels2plotHigh[c(1,2,3)]])
```

```{r risweepCovProcHDboot}
ses = c("bootRho", "bootParamRho", "cvRho", "oracleRho", "seBoot", "seBootParam", "seOracle"); names(ses) = ses
r2cisweepCIhigh = lapply(seq_len(nrow(gridSweepHighBoot)), function(i){
    lapply(sweepProcessHDboot[[i]], function(x){
        R2 = 1-x[['MSEhat']]/x[['margVar']]
        CI = R2 + outer(x[['ses']], Quants)
        rownames(x[["bootQuants"]])[1] = paste0(rownames(x[["bootQuants"]])[1], "Percentile")
        CI = rbind(CI, x[["bootQuants"]])
        CI[, 2] = sapply(CI[, 2], min, 1)
        CI
    })
})
r2cisweepNonCov = lapply(seq_len(nrow(gridSweepHighBoot)), function(i){
    trueR2 = 1 - sweepProcessHDboot[[i]][[1]]$true[["trueMSE"]]/sweepProcessHDboot[[i]][[1]]$true[["trueMargVar"]]
    vapply(r2cisweepCIhigh[[i]], FUN.VALUE = matrix(TRUE, nrow(r2cisweepCIhigh[[i]][[1]]),2), function(CI){
        cbind("under" = trueR2 < CI[,1], "over" = trueR2 > CI[,2]) 
    })
})
r2cisweepCovSum = t(sapply(r2cisweepNonCov, function(x) rowMeans(!apply(x, c(1,3), any, na.rm = TRUE) )))
r2cisweepWidth = lapply(seq_len(nrow(gridSweepHighBoot)), function(i){
    sapply(r2cisweepCIhigh[[i]], function(CI){
        apply(CI, 1, diff)
    })
})
r2cisweepWidthSumHD = t(sapply(r2cisweepWidth, rowMeans, na.rm = TRUE))
sweepSum = cbind(gridSweepHighBoot, r2cisweepCovSum)
sweepSumMoltHigh = melt(sweepSum, id.vars = names(gridSweepHighBoot), 
                        value.name = "Coverage", variable.name = 'Method')
sweepSumMoltHigh$betas = factor(sweepSumMoltHigh$betas)
sweepSumMoltHigh$Method = factor(sweepSumMoltHigh$Method, levels = methodLevels, labels = methodLabels)
```

```{r risweepCovHDboot, fig.cap = 'Coverage of the 95\\% confidence intervals for the .632  bootstrap \\rsq (y-axis) for different sample sizes (x-axis), methods (colour), signal strength (side panel) and number of inner bootstrap replicates (top panels) for 30 outer bootstrap samples in the high-dimensional scenario.\\label{fig:sweepCovHDBoot}'}
ggplot(data = sweepSumMoltHigh[with(sweepSumMoltHigh, bootRepsOuter == 30 & Method %in% labels2plotHigh),], aes(x = samSize, y = Coverage, col = Method, )) + geom_line() + facet_grid(betas~ bootReps, scale = "free_y") +
    geom_hline(yintercept = 1-sigLevel, linetype = 'dotted')+ ylab(bquote("Coverage of the 95% confidence intervals for the "*R^2)) + scale_colour_manual(values = methodColours[names(methodColours) %in% labels2plotHigh]) + xlab("Sample size") + scale_x_continuous(breaks = samSizeHigh) + theme(axis.text.x = element_text(angle=60))
```

```{r plotwidthsweepHDboot, fig.cap = 'Average width of the 95\\% confidence intervals for the .632 bootstrap \\rsq (y-axis) for different sample sizes (x-axis), method (colour), signal strength (side panel) and number of bootstrap replicates (top panels) for 30 outer bootstrap samples for the high-dimensional scenario. Some lines are truncated when all confidence interval estimations failed for a certain setting.\\label{fig:sweepWidthHDBoot}'}
sweepSumW = cbind(gridSweepHighBoot, r2cisweepWidthSumHD)
sweepSumMoltW = melt(sweepSumW, id.vars = names(gridSweepHighBoot), value.name = "Width_of_confidence_interval", variable.name = 'Method')
sweepSumMoltW$betas = factor(sweepSumMoltW$betas)
sweepSumMoltW$Method = factor(sweepSumMoltW$Method, levels = methodLevels, labels = methodLabels)
ggplot(data = sweepSumMoltW[with(sweepSumMoltW, bootRepsOuter == 30 &Method %in% labels2plotHigh),], aes(x = samSize, y = Width_of_confidence_interval, col = Method)) + geom_line() + facet_grid(betas~ bootReps, scale = "free_y")+ ylab(bquote("Width of the confidence interval for "*R^2)) + xlab("Sample size")+
    ylab(bquote("Average width of the 95% confidence intervals for the "*R^2)) +
    scale_colour_manual(values = methodColours[names(methodColours) %in% labels2plotHigh]) + scale_x_continuous(breaks = samSizeHigh) + theme(axis.text.x = element_text(angle=60)) 
```

```{r zTestHDboot, fig.cap = "Type I error of approximate one-sided z-tests that \\rsq $\\leq$ 0  (y-axis) as a function of sample size (x-axis), effect size (top panels) and number of outer bootstrap samples (side panels) for the .632 bootstrap in the high-dimensional scenario with number of bootstrap replicates 100. The horizontal dotted line indicates the significance level of 5\\%. Results are shown for all approximate true \\rsq values below 0 (see Table \\ref{tab:trueR2HD}). The nonparametric boostrap SE method does not control the type I error at the 5\\% significance level in all cases.\\label{fig:zTestHDBoot}"}
#Evaluate one-sided approximate z-test
idNullHDagg = R2mataggHd[, "R2"]<0
idNullHD <- sapply(seq_len(nrow(gridSweepHighBoot)), function(i){
            any(R2mataggHd[idNullHDagg, "betas"] %in% gridSweepHighBoot[i, "betas"] & 
                    R2mataggHd[idNullHDagg, "samSize"] %in% gridSweepHighBoot[i, "samSize"])
})
zTestEvalHD = lapply(which(idNullHD), function(i){
    sapply(sweepProcessHDboot[[i]], function(y){
        with(y, {
            R2hat = 1-MSEhat/margVar
            pnorm(R2hat/ses, lower.tail = FALSE)
        })
    })
})
#Calculate type I error
typeIerrorZ = cbind(gridSweepHighBoot[idNullHD, ], t(sapply(zTestEvalHD, function(x){
    rowMeans(x < sigLevel)
})))
typeIerrorZMolt = melt(typeIerrorZ, id.vars = colnames(gridSweepHighBoot), variable.name = "Method", value.name = "Type_I_error")
typeIerrorZMolt$Method = factor(typeIerrorZMolt$Method, levels = methodLevels, labels = methodLabels)
ggplot(data = typeIerrorZMolt[with(typeIerrorZMolt, Method %in% labels2plotHigh & bootReps==100),], aes_string(x = "samSize", y = "Type_I_error", col = "Method")) + geom_point(size = typeIerrorPointSize, position = position_dodge(width = dodgeTypeI)) + facet_grid(bootRepsOuter ~ betas) + xlab("Sample size") +geom_hline(linetype = "dotted", yintercept = sigLevel)+ scale_colour_manual(values = methodColours[names(methodColours) %in% intersect(typeIerrorZMolt$Method, labels2plot)]) + scale_x_continuous(breaks = samSizeHigh) + theme(axis.text.x = element_text(angle=60)) +ylab("Type I error")
```

\clearpage

# The distribution of the \hrsq \label{sec:R2dist}

```{r trueR2plot, fig.height = 5, fig.cap = "Quantile-quantile (QQ) plots of out-of-sample \\rsq estimated through cross-validation (y-axis) versus normal quantiles (x-axis) for different sample sizes (top panels) and signal strength (side panels) with 500 bootstrap instances and 200 cross-validation splits in the one-dimensional scenario. The dotted line indicates the maximum of 1. The \\hrsq behaves non-normally when the sample size is small.\\label{fig:trueR2plot}"}
ggplot(data = trueR2sAll[with(trueR2sAll, bootReps == 500 & cvSplitsSweep == 200) ,], aes(sample = R2)) + geom_qq(size = 0.5) + geom_qq_line() + facet_grid(betas ~ samSize)+
    xlab("Theoretical") + ylab("Observed") +geom_hline(linetype = "dotted", yintercept = 1)
```

```{r trueR2plotBoot, fig.height = 5, fig.cap = "Quantile-quantile (QQ) plots of out-of-sample \\rsq estimated through the .632 bootstrap (y-axis) versus normal quantiles (x-axis) for different sample sizes (top panels) and signal strength (side panels) with 200 inner and 50 outer bootstrap instances in the one-dimensional scenario. The dotted line indicates the maximum of 1. The \\hrsq behaves non-normally when the sample size is small.\\label{fig:trueR2plotBoot}"}
ggplot(data = trueR2sAllboot[with(trueR2sAllboot, bootReps==200 & bootRepsOuter == 50),], aes(sample = R2)) + geom_qq(size = 0.5) + geom_qq_line() + facet_grid(betas ~ samSize)+
    xlab("Theoretical") + ylab("Observed") + geom_hline(linetype = "dotted", yintercept = 1)
```

```{r trueR2plotHD, fig.height = 5, fig.cap = "Quantile-quantile (QQ) plots of \\rsq estimated through cross-validation (y-axis) versus normal quantiles (x-axis) for different sample sizes (top panels) and signal strength (side panels) in the high-dimensional scenario. The dotted line indicates the maximum of 1. The \\hrsq behaves non-normally when the effect size is large, presumably because of its proximity to its upper bound of 1. In addition, there is non-normality because unlike in the one-dimensional case, the estimated \\rsq rarely drops below 0, presumably because in these cases no features are selected in the high-dimensional model such that MSE=MST.\\label{fig:trueR2plotHD}"}
ggplot(data = trueR2sAllhd[with(trueR2sAllhd, bootReps==100 & cvSplits == 100),], aes(sample = R2)) + geom_qq(size = 0.5) + geom_qq_line() + facet_grid(betas ~ samSize) +
    xlab("Theoretical") + ylab("Observed") + geom_hline(linetype = "dotted", yintercept = 1)
```

```{r trueR2plotHDBoot, fig.height = 5, fig.cap = "Quantile-quantile (QQ) plots of \\rsq estimated through the .632 bootstrap (y-axis) versus normal quantiles (x-axis) for different sample sizes (top panels) and signal strength (side panels) in the high-dimensional scenario. The dotted line indicates the maximum of 1. The \\hrsq behaves non-normally in most scenarios.\\label{fig:trueR2plotHDboot}"}
ggplot(data = trueR2sAllhdBoot[trueR2sAllhdBoot$bootReps==100,], aes(sample = R2)) + geom_qq(size = 0.5) + geom_qq_line() + facet_grid(betas ~ samSize)+
    xlab("Theoretical") + ylab("Observed") +geom_hline(linetype = "dotted", yintercept = 1)
```

\clearpage

# The MSE in case of poor predictability \label{sec:R2null}

Here we derive an expression for the MSE by \textcite{Hastie2009} that explains why the R² becomes negative when the regressors have little predictive value of the outcome, or when the sample size is too low (see Tables \ref{tab:trueR2} and \ref{tab:trueR2HD}). 

\begin{equation}
\begin{aligned}
MSE &= E\left[(Y-\hY)^2\right]\\
&= E\left[\left((Y-\eY)-(\hY-\eY)\right)^2\right]\\
&= E\left[(Y-\eY)^2+(\hY-\eY)^2-2(Y-\eY)(\hY-\eY)\right]\\
&= E\left[(Y-\eY)^2\right]+ E\left[(\hY-\eY)^2\right]-2E\left[(\hY-\eY)(Y-\eY)\right]\\
&= \Var{Y}+ E\left[(\hY-\eY)^2\right]-2E\left[(\hY-\eY)(Y-\eY)\right]
\end{aligned}
\label{eq:MSEnull}
\end{equation}

For unbiased estimation, e.g. OLS, we have that $E(\hY) = \eY$, such that

\begin{equation}
\begin{aligned}
MSE &= \Var{Y}+ \Var{\hY} - 2\Cov{Y, \hY}
\end{aligned}
\label{eq:MSEnull2}
\end{equation}

In plain words, when the model is good enough such that the true outcome and prediction covary sufficiently, $\Var{\hY} - 2\Cov{Y, \hY} < \Var{\bar{Y}}$ and $MSE < MST$: the gain in prediction efficiency offsets the cost of having to estimate a model and $R^ 2>0$. However, in the complete null setting, $\Cov{Y, \hY}=0$, such that $MSE > MST$ and $R^2<0$. Note that when the prediction is simply $\bar{Y}$, $\Cov{Y, \bar{Y}}=0$, such that \eqref{eq:MSEnull2} simplifies to the MST and \rsq=0.

# Computation times

Computation times are a serious limiting factor for the application of data splitting algorithms. Table \ref{tab:compTimes} shows computation times of OLS averaged over 20 datasets with sample size $n=100$ on an Intel Core i5-11400H 2.70GHz processor. For nested cross-validation, 200 repeats of the 10-fold cross-validation splits were executed, for simple cross-validation only 10; in the latter case also 50 bootstrap samples were drawn. 200 inner and 50 outer bootstrap samples were drawn for .632 bootstrap  estimation. These values were chosen as they paint a realistic picture of the computation times needed to estimate the MSE as well as its SE. For cross-validation, bootstrap estimation of the SE is fastest, whereas for .632 bootstrap estimation, the delta method SE is fastest. The computation times of the estimation of the MST, the \rsq and its SE are negligible in comparison.

```{r compTimes, include = FALSE, fig.cap = "Computation times in seconds (y-axis) for simple and nested cross-validation and .632 bootstrap with standard error calculation (colours) for the one-dimensional scenario as a function of number of cross-validation splits and number of bootstrap samples respectively.\\label{tab:compTimes}"}
timeReps = 2e1
samSizeTime = 1e2; betaTime = 0; bootTime = 2e2; bootOuter = 50; splitsSimple = 10
id = seq_len(samSizeTime)
if(!file.exists(timeFile <- "simResults/timeObj.RData")){
    timeDatSets = lapply(seq_len(timeReps), function(r){
        trainDat = genDat(samSizeTime, 1, betas = betaTime)
    })
     cvTimes = sapply(timeDatSets, function(trainDat){
            system.time(nestedCV(trainDat, nOuterFolds, cvSplits = bootTime))[1]
        })

    cvTimesBoot = sapply(timeDatSets, function(trainDat){
            system.time(
                sapply(integer(bootOuter), function(x) {
                    trainDat$y = trainDat$y[id]; trainDat$x = trainDat$x[id,,drop = FALSE]
                    sapply(integer(splitsSimple), function(y) simpleCV(trainDat, nOuterFolds))
                    }))[1]
        })
    bootTimes = sapply(timeDatSets, function(trainDat){
            system.time({
                bootObjOOB = fullBoot(trainDat, bootTime, "oob")
                bootObjOOBests = processOob(bootObjOOB)
                bootObj632 = fullBoot(trainDat, bootReps = bootTime, bootMethod = "632", 
                bootRepsOuter = NULL, jackknife = FALSE)
            bootObj632ests = process632(bootObj632, oobObj = bootObjOOBests$procOb)})[1]
        })
    bootTimesBoot = sapply(timeDatSets, function(trainDat){
            system.time({
                lapply(integer(bootOuter), function(t){
                    trainDat$y = trainDat$y[id]; trainDat$x = trainDat$x[id,,drop = FALSE]
                bootObj632 = fullBoot(trainDat, bootReps = bootTime, bootMethod = "632", 
                bootRepsOuter = NULL, jackknife = FALSE)})
        })[1]
    })
    save(timeDatSets, cvTimes, cvTimesBoot, bootTimes, bootTimesBoot, file = timeFile )
} else load(timeFile)
```

```{r compTimesTab, results = "asis"}
timesTab = cbind("Cross-validation" = c(mean(cvTimes), mean(cvTimesBoot)), "Bootstrap .632" = c(mean(bootTimes), mean(bootTimesBoot)))
rownames(timesTab) = c("Delta method SE", "Bootstrap SE")
print(xtable(timesTab, digits = 3, caption = "\\label{tab:compTimes}Computation times in seconds for delta method and bootstrap estimation of standard error for cross-validation and bootstrap .632 estimation of the MSE."), comment = FALSE)
```

# Software \label{sec:soft}

All analyses were run in the R programming language, all version info can be found below.

```{r sessionInfo}
sessionInfo()
```

\printbibliography